{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: code to prevent run time disconnect\n",
        "\n",
        "# This code will keep the Colab runtime active by periodically sending a request to the server.\n",
        "\n",
        "import time\n",
        "import IPython\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        "function ClickConnect(){\n",
        "  console.log(\"Working\");\n",
        "  document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect,600)\n",
        "'''))\n",
        "\n",
        "print(\"Colab will remain active. Do not close this tab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "N6v90c5C7njC",
        "outputId": "4e9f6a4a-6da9-42f2-a2d3-c144296c3ea6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "function ClickConnect(){\n",
              "  console.log(\"Working\");\n",
              "  document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}\n",
              "setInterval(ClickConnect,600)\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab will remain active. Do not close this tab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djni4GQlYsc_",
        "outputId": "10e88c68-0fab-40c3-958b-1168a2963c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/klemenko/kitti-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22.5G/22.5G [04:15<00:00, 94.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK./root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1\n",
        "# /content/labels_with_dont_care\n",
        "import kagglehub\n",
        "klemenko_kitti_dataset_path = kagglehub.dataset_download('klemenko/kitti-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ybuXWu-SsC6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82244242-6d32-4362-cce3-f56db3507e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "print(klemenko_kitti_dataset_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iXziIp4WYsdC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import YOLOv7 library\n",
        "import sys\n",
        "sys.path.append('yolov7')  # Add YOLOv7 to the path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsbdbb78YsdD"
      },
      "source": [
        "# 1. Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n0USoyjHYsdD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac380a1-b77f-47b2-f02c-3e85e3ca58b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "data.yaml content:\n",
            "{'train': '/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train', 'val': '/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid', 'nc': 9, 'names': ['Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare']}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# KITTI dataset configuration\n",
        "KITTI_BASE_DIR = '/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1'\n",
        "\"\"\"str: The base directory where the KITTI dataset is located.\"\"\"\n",
        "\n",
        "IMAGE_DIR = Path(KITTI_BASE_DIR) / 'data_object_image_2' / 'training' / 'image_2'\n",
        "\"\"\"Path: Directory containing KITTI training images.\"\"\"\n",
        "\n",
        "LABEL_DIR = Path(KITTI_BASE_DIR) / 'data_object_label_2' / 'training' / 'label_2'\n",
        "\"\"\"Path: Directory containing KITTI training labels.\"\"\"\n",
        "\n",
        "TRAIN_DIR = Path(KITTI_BASE_DIR)/'train'\n",
        "\"\"\"Path: Directory where training images and labels will be stored in YOLOv7 format.\"\"\"\n",
        "\n",
        "VALID_DIR = Path(KITTI_BASE_DIR)/'valid'\n",
        "\"\"\"Path: Directory where validation images and labels will be stored in YOLOv7 format.\"\"\"\n",
        "\n",
        "LABELS_DIR = Path(KITTI_BASE_DIR)/'labels_with_dont_care'\n",
        "\"\"\"Path: Directory where YOLOv7-formatted labels will be stored.\"\"\"\n",
        "\n",
        "CLASSES = [\n",
        "    'Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting',\n",
        "    'Cyclist', 'Tram', 'Misc', 'DontCare'\n",
        "]\n",
        "\"\"\"\n",
        "list of str: List of class names included in the KITTI dataset.\n",
        "'CLASSES' should reflect all possible object categories for detection.\n",
        "\"\"\"\n",
        "\n",
        "# YOLOv7 model configuration\n",
        "WEIGHTS = 'yolov7.pt'  # Pretrained weights for YOLOv7\n",
        "\"\"\"str: Path to the YOLOv7 pretrained weights file.\"\"\"\n",
        "\n",
        "EPOCHS = 50\n",
        "\"\"\"int: Number of epochs for training. Adjust this value based on dataset size and desired training time.\"\"\"\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\"\"\"int: Batch size used during training. Adjust based on GPU memory constraints.\"\"\"\n",
        "\n",
        "IMG_SIZE = 640\n",
        "\"\"\"int: The size (height and width) of the input images for the model.\"\"\"\n",
        "\n",
        "CONFIDENCE_THRESHOLD = 0.25\n",
        "\"\"\"float: The confidence threshold for predictions during validation and testing.\"\"\"\n",
        "\n",
        "PROJECT_NAME = 'YOLOv7-KITTI'\n",
        "\"\"\"str: The name of the project folder where YOLOv7 results will be saved.\"\"\"\n",
        "\n",
        "EXPERIMENT_NAME = 'exp1'\n",
        "\"\"\"str: The name of the experiment folder within the project directory to store this run's results.\"\"\"\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\"\"\"str: The device to use for training and inference, defaults to GPU if available.\"\"\"\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path for the data.yaml file for YOLOv7\n",
        "DATA_CONFIG_PATH = '/content/data.yaml'\n",
        "\n",
        "# Prepare the data.yaml file with necessary paths and class names for YOLOv7\n",
        "data_config = {\n",
        "    'train': str(Path(TRAIN_DIR).resolve()),\n",
        "    'val': str(Path(VALID_DIR).resolve()),\n",
        "    'nc': len(CLASSES),\n",
        "    'names': CLASSES\n",
        "}\n",
        "\n",
        "# Write the data.yaml configuration for YOLOv7\n",
        "with open(DATA_CONFIG_PATH, 'w', encoding='utf-8') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "# Print out the data.yaml content for verification\n",
        "print(f\"data.yaml content:\\n{data_config}\")\n",
        "\n",
        "# YOLOv7 Training Command\n",
        "# Modify this line to execute the YOLOv7 training\n",
        "os.system(f\"\"\"\n",
        "python train.py --weights {WEIGHTS} \\\n",
        "--cfg ./models/yolov7.yaml \\\n",
        "--data {DATA_CONFIG_PATH} \\\n",
        "--epochs {EPOCHS} \\\n",
        "--batch-size {BATCH_SIZE} \\\n",
        "--img-size {IMG_SIZE} \\\n",
        "--project {PROJECT_NAME} \\\n",
        "--name {EXPERIMENT_NAME} \\\n",
        "--device {device} \\\n",
        "--exist-ok\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfyFbuOlYsdE"
      },
      "source": [
        "# 2. Data Preparation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qVwHwhr1YsdE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "# Class names for KITTI dataset\n",
        "CLASSES = [\n",
        "    'Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting',\n",
        "    'Cyclist', 'Tram', 'Misc', 'DontCare'\n",
        "]\n",
        "\"\"\"\n",
        "List of class names included in the KITTI dataset.\n",
        "'CLASSES' should reflect all possible object categories for detection.\n",
        "\"\"\"\n",
        "\n",
        "CLAZZ_NUMBERS = {name: idx for idx, name in enumerate(CLASSES)}\n",
        "\"\"\"\n",
        "dict: A mapping from class names to numeric labels.\n",
        "The numeric labels are used by YOLO for class indices.\n",
        "\"\"\"\n",
        "\n",
        "def convert_bbox_to_yolo(bbox, size):\n",
        "    \"\"\"\n",
        "    Convert KITTI bounding box coordinates to YOLO format.\n",
        "\n",
        "    Args:\n",
        "        bbox (tuple of float): Bounding box coordinates in the format (left, right, top, bottom).\n",
        "        size (tuple of int): Image size as (width, height).\n",
        "\n",
        "    Returns:\n",
        "        tuple of float: YOLO-formatted bounding box as (x_center, y_center, width, height) normalized by image size.\n",
        "    \"\"\"\n",
        "    dw = 1.0 / size[0]\n",
        "    dh = 1.0 / size[1]\n",
        "    x_center = (bbox[0] + bbox[1]) / 2.0\n",
        "    y_center = (bbox[2] + bbox[3]) / 2.0\n",
        "    width = bbox[1] - bbox[0]\n",
        "    height = bbox[3] - bbox[2]\n",
        "    x_center *= dw\n",
        "    width *= dw\n",
        "    y_center *= dh\n",
        "    height *= dh\n",
        "    return x_center, y_center, width, height\n",
        "\n",
        "def parse_kitti_label_file(lbl_path, img_path):\n",
        "    \"\"\"\n",
        "    Parse a KITTI label file and convert the bounding boxes to YOLOv7 format.\n",
        "\n",
        "    Args:\n",
        "        lbl_path (Path): Path to the KITTI label file (in KITTI text format).\n",
        "        img_path (Path): Path to the corresponding image file.\n",
        "\n",
        "    Returns:\n",
        "        list of tuple: A list of YOLOv7-formatted bounding boxes. Each element is\n",
        "        (class_idx, x_center, y_center, width, height).\n",
        "    \"\"\"\n",
        "    with open(lbl_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.read().strip().split('\\n')\n",
        "\n",
        "    yolo_labels = []\n",
        "    if not img_path.exists():\n",
        "        # If the image doesn't exist, skip processing labels\n",
        "        return yolo_labels\n",
        "\n",
        "    img_size = Image.open(img_path).size  # (width, height)\n",
        "\n",
        "    for line in lines:\n",
        "        parts = line.split()\n",
        "        clazz = parts[0]\n",
        "        if clazz not in CLAZZ_NUMBERS:\n",
        "            # Skip classes not in our mapping\n",
        "            continue\n",
        "\n",
        "        # KITTI format:\n",
        "        # type, truncated, occluded, alpha, bbox_left, bbox_top, bbox_right, bbox_bottom, ...\n",
        "        # Indices:  0    ,    1     ,   2     ,   3  ,    4     ,    5    ,     6     ,      7    ...\n",
        "        # Example: Car 0.00 0 1.57 148.00 174.00 350.00 325.00 ...\n",
        "        # The bounding box coordinates: left = parts[4], top = parts[5], right = parts[6], bottom = parts[7]\n",
        "        bbox_left = float(parts[4])\n",
        "        bbox_top = float(parts[5])\n",
        "        bbox_right = float(parts[6])\n",
        "        bbox_bottom = float(parts[7])\n",
        "        bbox = (bbox_left, bbox_right, bbox_top, bbox_bottom)\n",
        "\n",
        "        # Convert bounding box to YOLO format (normalized)\n",
        "        x_center, y_center, width, height = convert_bbox_to_yolo(bbox, img_size)\n",
        "        clazz_number = CLAZZ_NUMBERS[clazz]\n",
        "\n",
        "        # YOLOv7 format: class x_center y_center width height\n",
        "        yolo_labels.append((clazz_number, x_center, y_center, width, height))\n",
        "\n",
        "    return yolo_labels\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvVH8XR0YsdF"
      },
      "source": [
        "# 3. Generate YOLO labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vHnBl36UYsdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2719f61a-8343-4b09-d246-28d3633cac7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO format labels have been generated in: /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/labels_with_dont_care\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Check if the labels directory exists, create it if not\n",
        "if not LABELS_DIR.exists():\n",
        "    LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Sort image and label paths\n",
        "image_paths = sorted(list(IMAGE_DIR.glob('*.png')))\n",
        "label_paths = sorted(list(LABEL_DIR.glob('*.txt')))\n",
        "\n",
        "# Process each image and its corresponding label file\n",
        "for img_path in image_paths:\n",
        "    lbl_path = LABEL_DIR / f\"{img_path.stem}.txt\"\n",
        "\n",
        "    # Ensure that the label file exists\n",
        "    if lbl_path.exists():\n",
        "        # Parse KITTI label to YOLOv7 format\n",
        "        yolo_labels = parse_kitti_label_file(lbl_path, img_path)\n",
        "\n",
        "        # Define the output label file path\n",
        "        yolo_label_path = LABELS_DIR / f\"{img_path.stem}.txt\"\n",
        "\n",
        "        # Write the YOLOv7-formatted labels to the label file\n",
        "        with open(yolo_label_path, 'w', encoding='utf-8') as lf:\n",
        "            for lbl in yolo_labels:\n",
        "                # Write each label with 6 decimal places for each value\n",
        "                lf.write(\" \".join(f\"{val:.6f}\" for val in lbl) + \"\\n\")\n",
        "\n",
        "print(f\"YOLO format labels have been generated in: {LABELS_DIR.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNFi6m5CYsdF"
      },
      "source": [
        "# 4. Split Dataset into Train and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaBKKlXxYsdG",
        "outputId": "ef847901-e609-464f-fd68-7e00bc4a345e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 6732, Validation samples: 749\n",
            "Training data copied to /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train/images and /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train/labels\n",
            "Validation data copied to /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/images and /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/labels\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a list of image and label pairs for labels that exist in LABELS_DIR\n",
        "labels_for_images = [(img_path, LABELS_DIR / f\"{img_path.stem}.txt\")\n",
        "                     for img_path in image_paths\n",
        "                     if (LABELS_DIR / f\"{img_path.stem}.txt\").exists()]\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_pairs, valid_pairs = train_test_split(\n",
        "    labels_for_images,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Print the number of training and validation samples\n",
        "print(f\"Training samples: {len(train_pairs)}, Validation samples: {len(valid_pairs)}\")\n",
        "\n",
        "# Create directories for YOLOv7 data structure (images and labels)\n",
        "for folder in [TRAIN_DIR, VALID_DIR]:\n",
        "    if folder.exists():\n",
        "        shutil.rmtree(folder)  # Remove existing folder contents\n",
        "    folder.mkdir(parents=True, exist_ok=True)  # Create the folder\n",
        "    (folder / 'images').mkdir(parents=True, exist_ok=True)  # Create images subfolder\n",
        "    (folder / 'labels').mkdir(parents=True, exist_ok=True)  # Create labels subfolder\n",
        "\n",
        "# Copy images and labels to the training folder\n",
        "for img_path, lbl_path in train_pairs:\n",
        "    shutil.copy(img_path, TRAIN_DIR / 'images' / img_path.name)  # Copy image\n",
        "    shutil.copy(lbl_path, TRAIN_DIR / 'labels' / lbl_path.name)  # Copy label\n",
        "\n",
        "# Copy images and labels to the validation folder\n",
        "for img_path, lbl_path in valid_pairs:\n",
        "    shutil.copy(img_path, VALID_DIR / 'images' / img_path.name)  # Copy image\n",
        "    shutil.copy(lbl_path, VALID_DIR / 'labels' / lbl_path.name)  # Copy label\n",
        "\n",
        "# Print where the data is copied\n",
        "print(f\"Training data copied to {TRAIN_DIR / 'images'} and {TRAIN_DIR / 'labels'}\")\n",
        "print(f\"Validation data copied to {VALID_DIR / 'images'} and {VALID_DIR / 'labels'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAfxeiRtYsdG"
      },
      "source": [
        "# 5. Create data.yaml File for YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw4SxV1kEHQ8",
        "outputId": "e0a10a99-aeba-4059-8e91-3137a7990663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv7 data.yaml file created with content:\n",
            "{'train': '/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train/images', 'val': '/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/images', 'nc': 9, 'names': ['Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare']}\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the class names for the KITTI dataset\n",
        "CLASSES = [\n",
        "    'Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting',\n",
        "    'Cyclist', 'Tram', 'Misc', 'DontCare'\n",
        "]\n",
        "\"\"\"\n",
        "list of str: List of class names in the KITTI dataset.\n",
        "\"\"\"\n",
        "\n",
        "# Define the directories for training and validation images\n",
        "TRAIN_IMAGES_DIR = Path(KITTI_BASE_DIR) / 'train' / 'images'\n",
        "VALID_IMAGES_DIR = Path(KITTI_BASE_DIR) / 'valid' / 'images'\n",
        "\n",
        "# Define the path for the data.yaml file\n",
        "YOLOV7_DATA_CONFIG_PATH = Path(KITTI_BASE_DIR) / 'yolov7_data.yaml'\n",
        "\n",
        "# Prepare the data configuration dictionary for YOLOv7\n",
        "yolov7_data_config = {\n",
        "    'train': str(TRAIN_IMAGES_DIR.resolve()),  # Absolute path to training images\n",
        "    'val': str(VALID_IMAGES_DIR.resolve()),   # Absolute path to validation images\n",
        "    'nc': len(CLASSES),                       # Number of classes\n",
        "    'names': CLASSES                          # List of class names\n",
        "}\n",
        "\n",
        "# Write the data configuration to the yolov7_data.yaml file\n",
        "with open(YOLOV7_DATA_CONFIG_PATH, 'w', encoding='utf-8') as f:\n",
        "    yaml.dump(yolov7_data_config, f, default_flow_style=False)\n",
        "\n",
        "# Output the content of the generated yolov7_data.yaml file\n",
        "print(\"YOLOv7 data.yaml file created with content:\")\n",
        "print(yolov7_data_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbYw3sSQ3Lco",
        "outputId": "7209fae6-1e9d-4dbb-9c76-b48c611d91d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yolov8\n",
            "  Downloading yolov8-0.0.2-py37.py38.py39-none-any.whl.metadata (2.0 kB)\n",
            "Collecting yolov5 (from yolov8)\n",
            "  Downloading yolov5-7.0.14-py37.py38.py39.py310-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (3.1.44)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (11.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (1.13.1)\n",
            "Collecting thop>=0.1.1 (from yolov5->yolov8)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (4.67.1)\n",
            "Collecting ultralytics>=8.0.100 (from yolov5->yolov8)\n",
            "  Downloading ultralytics-8.3.63-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (2.17.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (75.1.0)\n",
            "Collecting fire (from yolov5->yolov8)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3>=1.19.1 (from yolov5->yolov8)\n",
            "  Downloading boto3-1.36.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sahi>=0.11.10 (from yolov5->yolov8)\n",
            "  Downloading sahi-0.11.20-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting huggingface-hub<0.25.0,>=0.12.0 (from yolov5->yolov8)\n",
            "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting roboflow>=0.2.29 (from yolov5->yolov8)\n",
            "  Downloading roboflow-1.1.50-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting botocore<1.37.0,>=1.36.1 (from boto3>=1.19.1->yolov5->yolov8)\n",
            "  Downloading botocore-1.36.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.19.1->yolov5->yolov8)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3>=1.19.1->yolov5->yolov8)\n",
            "  Downloading s3transfer-0.11.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->yolov5->yolov8) (4.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5->yolov8) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5->yolov8) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5->yolov8) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5->yolov8) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->yolov5->yolov8) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->yolov5->yolov8) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5->yolov8) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5->yolov8) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5->yolov8) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5->yolov8) (2024.12.14)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.23.0->yolov5->yolov8)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.29->yolov5->yolov8) (4.10.0.84)\n",
            "Collecting python-dotenv (from roboflow>=0.2.29->yolov5->yolov8)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.29->yolov5->yolov8) (1.17.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.29->yolov5->yolov8) (1.0.0)\n",
            "Collecting filetype (from roboflow>=0.2.29->yolov5->yolov8)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from sahi>=0.11.10->yolov5->yolov8) (2.0.6)\n",
            "Collecting pybboxes==0.1.6 (from sahi>=0.11.10->yolov5->yolov8)\n",
            "  Downloading pybboxes-0.1.6-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting terminaltables (from sahi>=0.11.10->yolov5->yolov8)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sahi>=0.11.10->yolov5->yolov8) (8.1.8)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (1.69.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (4.25.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (3.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->yolov5->yolov8) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->yolov5->yolov8) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.0.100->yolov5->yolov8) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.0.100->yolov5->yolov8)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->yolov5->yolov8) (2.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->yolov5->yolov8) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->yolov5->yolov8) (3.0.2)\n",
            "Downloading yolov8-0.0.2-py37.py38.py39-none-any.whl (1.9 kB)\n",
            "Downloading yolov5-7.0.14-py37.py38.py39.py310-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.5/953.5 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.36.1-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roboflow-1.1.50-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sahi-0.11.20-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybboxes-0.1.6-py3-none-any.whl (24 kB)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading ultralytics-8.3.63-py3-none-any.whl (910 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m910.2/910.2 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.36.1-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=9926c50fa4168db84faf1030235e8734cdb845f7fdff77bf421cc3ce6c7c8a2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: filetype, terminaltables, python-dotenv, pybboxes, jmespath, idna, fire, botocore, sahi, s3transfer, huggingface-hub, ultralytics-thop, thop, roboflow, boto3, ultralytics, yolov5, yolov8\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.27.1\n",
            "    Uninstalling huggingface-hub-0.27.1:\n",
            "      Successfully uninstalled huggingface-hub-0.27.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.24.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed boto3-1.36.1 botocore-1.36.1 filetype-1.2.0 fire-0.7.0 huggingface-hub-0.24.7 idna-3.7 jmespath-1.0.1 pybboxes-0.1.6 python-dotenv-1.0.1 roboflow-1.1.50 s3transfer-0.11.1 sahi-0.11.20 terminaltables-3.1.10 thop-0.1.1.post2209072238 ultralytics-8.3.63 ultralytics-thop-2.0.14 yolov5-7.0.14 yolov8-0.0.2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install yolov8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0PyBFQxYsdG"
      },
      "source": [
        "# 6. Train the YOLO11 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBFYFegxZJgq"
      },
      "source": [
        "MODEL ARCHITECTURE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuE458F05bdO",
        "outputId": "b05ef923-a852-4cf5-eb2a-2c4c5fc8abb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.63)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Setup complete. Using torch 2.5.1+cu121 (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "# Install YOLOv8\n",
        "!pip install ultralytics  # Install the ultralytics library for YOLOv8\n",
        "\n",
        "# Import the library and check setup\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Print system and environment information\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lei-dUYfhiOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics -q"
      ],
      "metadata": {
        "id": "8Rq-HDXsusp-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import json\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm\n",
        "import shutil\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "0y5-WSb6uwFA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Define configuration\n",
        "MODEL_ARCH = 'yolov8n.pt'  # YOLOv8 Nano model (change to 'yolov8s.pt', 'yolov8m.pt', etc., for other versions)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Define the training parameters\n",
        "DATA_CONFIG = '/content/data.yaml'  # Path to the data.yaml file\n",
        "EPOCHS = 50  # Number of epochs (adjust as needed)\n",
        "BATCH_SIZE = 16  # Batch size (adjust based on system resources)\n",
        "IMG_SIZE = 640  # Input image size\n",
        "CONFIDENCE_THRESHOLD = 0.25  # Confidence threshold for validation\n",
        "\n",
        "PROJECT_NAME = 'YOLOv8-KITTI'  # Project folder name\n",
        "EXPERIMENT_NAME = 'exp1'  # Experiment name\n",
        "\n",
        "# Initialize the model\n",
        "model = YOLO(MODEL_ARCH)\n",
        "\n",
        "# Train the model\n",
        "train_results = model.train(\n",
        "    data=DATA_CONFIG,\n",
        "    epochs=EPOCHS,\n",
        "    batch=BATCH_SIZE,\n",
        "    imgsz=IMG_SIZE,\n",
        "    project=PROJECT_NAME,\n",
        "    name=EXPERIMENT_NAME,\n",
        "    device=device,\n",
        "    exist_ok=True  # Overwrite the existing project/experiment folder if it exists\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwo012ohhm3p",
        "outputId": "fa6deee6-cc53-4720-b136-12ea228af59a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 111MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.63 🚀 Python-3.11.11 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=YOLOv8-KITTI, name=exp1, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=YOLOv8-KITTI/exp1\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 22.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=9\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,012,603 parameters, 3,012,587 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir YOLOv8-KITTI/exp1', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 97.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train/labels... 6732 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6732/6732 [00:37<00:00, 181.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/labels... 749 images, 0 backgrounds, 0 corrupt: 100%|██████████| 749/749 [00:04<00:00, 157.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to YOLOv8-KITTI/exp1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mYOLOv8-KITTI/exp1\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      2.58G      1.491       1.92      1.103        246        640: 100%|██████████| 421/421 [03:24<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:13<00:00,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.487      0.342      0.325      0.192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      2.65G      1.374      1.263      1.072        162        640: 100%|██████████| 421/421 [03:21<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.544      0.386      0.415      0.245\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      2.54G      1.319      1.115      1.061        125        640: 100%|██████████| 421/421 [03:19<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:13<00:00,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.483      0.406      0.422      0.249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      2.57G      1.293      1.036      1.052        174        640: 100%|██████████| 421/421 [03:19<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.534      0.465      0.501      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      2.52G      1.257     0.9755       1.04        158        640: 100%|██████████| 421/421 [03:20<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.566      0.481      0.514      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      2.56G      1.233     0.9299      1.031        195        640: 100%|██████████| 421/421 [03:21<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:13<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.588      0.528      0.567      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      2.55G      1.215     0.8954      1.026        197        640: 100%|██████████| 421/421 [03:22<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425       0.58      0.566      0.584      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50      2.56G      1.194     0.8673      1.018        160        640: 100%|██████████| 421/421 [03:16<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:13<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.643      0.519      0.589      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50       2.6G      1.175     0.8511      1.012        180        640: 100%|██████████| 421/421 [03:24<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.734      0.495      0.605      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      2.47G       1.16     0.8321      1.005        201        640: 100%|██████████| 421/421 [03:23<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:13<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.638      0.574      0.625      0.393\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      2.88G      1.154     0.8191          1        195        640: 100%|██████████| 421/421 [03:21<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.695      0.551      0.618      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      2.62G      1.142      0.804     0.9998        139        640: 100%|██████████| 421/421 [03:18<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.707      0.585      0.654      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      2.54G      1.125     0.7825     0.9911        183        640: 100%|██████████| 421/421 [03:22<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.728      0.584      0.665      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      2.74G      1.115     0.7738     0.9901        157        640: 100%|██████████| 421/421 [03:18<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.724      0.572      0.653      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      2.53G      1.109     0.7613     0.9882        107        640: 100%|██████████| 421/421 [03:18<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425       0.69      0.646      0.689      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      2.33G      1.089     0.7477      0.981        154        640: 100%|██████████| 421/421 [03:19<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.703      0.606      0.673      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      2.62G      1.084     0.7423     0.9797        176        640: 100%|██████████| 421/421 [03:18<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.686      0.635      0.686       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      2.34G      1.077     0.7321     0.9783        164        640: 100%|██████████| 421/421 [03:17<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.762      0.611      0.697      0.455\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      2.55G      1.072      0.725     0.9743        199        640: 100%|██████████| 421/421 [03:15<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.693      0.655      0.711      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      2.54G      1.055      0.715     0.9703        256        640: 100%|██████████| 421/421 [03:14<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.732       0.65       0.71      0.462\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      2.42G      1.051     0.7044     0.9675        167        640: 100%|██████████| 421/421 [03:11<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425       0.67      0.684      0.723      0.475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50      2.53G      1.043      0.702     0.9646        113        640: 100%|██████████| 421/421 [03:11<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.717      0.657      0.718      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      2.45G      1.037     0.6928      0.962        168        640: 100%|██████████| 421/421 [03:09<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.742      0.664      0.733      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      2.45G      1.036     0.6902     0.9635        117        640: 100%|██████████| 421/421 [03:16<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.721      0.667      0.722      0.486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      2.41G      1.026     0.6815     0.9595        196        640: 100%|██████████| 421/421 [03:17<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.741      0.692      0.744        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      2.34G       1.02     0.6761     0.9566        190        640: 100%|██████████| 421/421 [03:10<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.785      0.678      0.748      0.502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      2.49G      1.013     0.6692     0.9548        179        640: 100%|██████████| 421/421 [03:13<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.788      0.665      0.743      0.503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      2.76G      1.007     0.6637     0.9525        212        640: 100%|██████████| 421/421 [03:11<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.743      0.687      0.745      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50       2.5G      1.008     0.6607     0.9518        182        640: 100%|██████████| 421/421 [03:12<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.759      0.702      0.764      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      2.34G     0.9971     0.6537     0.9497        198        640: 100%|██████████| 421/421 [03:12<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.748      0.708      0.759      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      2.58G      0.988     0.6482     0.9487        181        640: 100%|██████████| 421/421 [03:07<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.773      0.714      0.769      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50      2.46G     0.9829     0.6427     0.9455        171        640: 100%|██████████| 421/421 [03:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.756      0.711      0.765       0.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      2.48G      0.979     0.6397     0.9427        148        640: 100%|██████████| 421/421 [03:05<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.808      0.692      0.769       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      2.45G     0.9726     0.6317     0.9388        174        640: 100%|██████████| 421/421 [03:06<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425       0.79      0.719      0.782      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50      2.53G     0.9679      0.629     0.9391        187        640: 100%|██████████| 421/421 [03:08<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.795      0.715      0.787      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      2.45G     0.9593     0.6243     0.9395        195        640: 100%|██████████| 421/421 [03:07<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.794      0.716      0.775      0.531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      2.51G       0.95     0.6144     0.9345        141        640: 100%|██████████| 421/421 [03:07<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.804      0.715      0.779      0.537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      2.53G      0.944      0.609     0.9303        207        640: 100%|██████████| 421/421 [03:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.779       0.74       0.79      0.544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      2.48G     0.9415     0.6104     0.9319        133        640: 100%|██████████| 421/421 [03:07<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425       0.79       0.73      0.792      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      2.69G     0.9354     0.6041     0.9291        129        640: 100%|██████████| 421/421 [03:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.792      0.728      0.792      0.552\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      2.24G     0.9236     0.5814     0.9228        101        640: 100%|██████████| 421/421 [03:09<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.785      0.709      0.779      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      2.18G      0.904     0.5694     0.9179         75        640: 100%|██████████| 421/421 [03:04<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.797      0.728      0.791      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      2.16G     0.9015     0.5626     0.9149         73        640: 100%|██████████| 421/421 [03:03<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.773      0.757      0.795      0.549\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      2.17G     0.8921     0.5583     0.9119         97        640: 100%|██████████| 421/421 [03:01<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.771      0.746      0.796      0.551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      2.25G     0.8851     0.5543     0.9086        104        640: 100%|██████████| 421/421 [02:59<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425       0.79      0.751      0.801      0.554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      2.18G      0.879     0.5487     0.9098         74        640: 100%|██████████| 421/421 [03:04<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.775       0.76      0.799      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50      2.16G     0.8743     0.5459     0.9068         86        640: 100%|██████████| 421/421 [03:06<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.835      0.737      0.806       0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50      2.18G     0.8666     0.5399     0.9049        102        640: 100%|██████████| 421/421 [03:00<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.839      0.716      0.803      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50      2.27G     0.8602     0.5364     0.9036         71        640: 100%|██████████| 421/421 [03:00<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.775      0.753      0.802      0.564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50      2.19G     0.8561     0.5325     0.9018         60        640: 100%|██████████| 421/421 [02:59<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.829      0.738      0.803      0.562\n",
            "\n",
            "50 epochs completed in 2.865 hours.\n",
            "Optimizer stripped from YOLOv8-KITTI/exp1/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from YOLOv8-KITTI/exp1/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating YOLOv8-KITTI/exp1/weights/best.pt...\n",
            "Ultralytics 8.3.63 🚀 Python-3.11.11 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:13<00:00,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.778      0.753      0.803      0.563\n",
            "                   Car        678       3040      0.887       0.93      0.961      0.773\n",
            "                   Van        223        296      0.859      0.895      0.948      0.735\n",
            "                 Truck        102        104      0.913      0.942      0.976      0.798\n",
            "            Pedestrian        179        441      0.769      0.714      0.779      0.431\n",
            "        Person_sitting         12         25      0.596        0.6      0.656      0.409\n",
            "               Cyclist        124        174      0.824      0.787      0.849      0.547\n",
            "                  Tram         29         56      0.823      0.913      0.955        0.7\n",
            "                  Misc         75         91       0.82      0.803      0.832      0.586\n",
            "              DontCare        567       1198      0.511       0.19      0.273     0.0911\n",
            "Speed: 0.2ms preprocess, 1.3ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mYOLOv8-KITTI/exp1\u001b[0m\n",
            "\n",
            "Training completed!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMc_KA_dYsdG"
      },
      "source": [
        "# 7. Validate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xav_3j84YsdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72001174-e639-4867-8e1a-58fc196d77d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary (fused): 168 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/labels.cache... 749 images, 0 backgrounds, 0 corrupt: 100%|██████████| 749/749 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:10<00:00,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.769       0.77      0.814      0.609\n",
            "                   Car        678       3040      0.872      0.934      0.955      0.802\n",
            "                   Van        223        296      0.845      0.905      0.935      0.768\n",
            "                 Truck        102        104      0.916      0.942      0.962      0.824\n",
            "            Pedestrian        179        441      0.742      0.726      0.799      0.486\n",
            "        Person_sitting         12         25       0.63       0.68      0.682      0.453\n",
            "               Cyclist        124        174      0.792      0.787      0.862      0.608\n",
            "                  Tram         29         56      0.836      0.911      0.929       0.73\n",
            "                  Misc         75         91      0.804      0.813      0.871      0.665\n",
            "              DontCare        567       1198      0.485       0.23      0.332      0.141\n",
            "Speed: 0.1ms preprocess, 1.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation completed!\n",
            "\n",
            "Validation Results (raw DetMetrics object):\n",
            "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
            "\n",
            "ap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
            "box: ultralytics.utils.metrics.Metric object\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7cdca697da50>\n",
            "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.026269,    0.013135,           0],\n",
            "       [          1,           1,           1, ...,    0.017893,   0.0089463,           0],\n",
            "       [          1,           1,           1, ...,    0.031783,    0.015891,           0],\n",
            "       ...,\n",
            "       [          1,           1,           1, ...,    0.018747,   0.0093733,           0],\n",
            "       [          1,           1,           1, ...,   0.0086199,   0.0043099,           0],\n",
            "       [    0.81818,     0.81818,     0.81818, ...,   0.0012618,   0.0006309,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.90167,     0.90167,     0.90167, ...,           0,           0,           0],\n",
            "       [    0.87439,     0.87439,     0.87439, ...,           0,           0,           0],\n",
            "       [    0.92891,     0.92891,     0.92891, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.87179,     0.87179,     0.87179, ...,           0,           0,           0],\n",
            "       [    0.80874,     0.80874,     0.80874, ...,           0,           0,           0],\n",
            "       [    0.31239,     0.31239,     0.31239, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.87189,     0.87189,     0.87189, ...,           1,           1,           1],\n",
            "       [    0.84543,     0.84543,     0.84543, ...,           1,           1,           1],\n",
            "       [    0.91589,     0.91589,     0.91589, ...,           1,           1,           1],\n",
            "       ...,\n",
            "       [    0.83607,     0.83607,     0.83607, ...,           1,           1,           1],\n",
            "       [    0.80435,     0.80435,     0.80435, ...,           1,           1,           1],\n",
            "       [    0.48506,     0.48506,     0.48506, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.93355,     0.93355,     0.93355, ...,           0,           0,           0],\n",
            "       [    0.90541,     0.90541,     0.90541, ...,           0,           0,           0],\n",
            "       [    0.94231,     0.94231,     0.94231, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.91071,     0.91071,     0.91071, ...,           0,           0,           0],\n",
            "       [    0.81319,     0.81319,     0.81319, ...,           0,           0,           0],\n",
            "       [    0.23038,     0.23038,     0.23038, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "fitness: 0.6291552459817952\n",
            "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
            "maps: array([    0.80247,      0.7683,     0.82437,     0.48582,     0.45263,     0.60817,     0.72971,     0.66521,     0.14071])\n",
            "names: {0: 'Car', 1: 'Van', 2: 'Truck', 3: 'Pedestrian', 4: 'Person_sitting', 5: 'Cyclist', 6: 'Tram', 7: 'Misc', 8: 'DontCare'}\n",
            "plot: False\n",
            "results_dict: {'metrics/precision(B)': 0.7691860634455633, 'metrics/recall(B)': 0.769836745120831, 'metrics/mAP50(B)': 0.8141488421254083, 'metrics/mAP50-95(B)': 0.6086004019658381, 'fitness': 0.6291552459817952}\n",
            "save_dir: PosixPath('runs/detect/val2')\n",
            "speed: {'preprocess': 0.10993420202359656, 'inference': 1.9164365506140348, 'loss': 0.0007547269039383241, 'postprocess': 1.8779578928317182}\n",
            "task: 'detect'\n",
            "\n",
            "Box Metrics:\n",
            "ultralytics.utils.metrics.Metric object with attributes:\n",
            "\n",
            "all_ap: array([[    0.95535,     0.95257,      0.9487,     0.94219,     0.93254,     0.90751,     0.86715,     0.76662,     0.57301,     0.17911],\n",
            "       [    0.93545,     0.93347,     0.93347,     0.92133,     0.90651,     0.87972,     0.81673,     0.70638,     0.48091,     0.16903],\n",
            "       [    0.96233,     0.96233,     0.95701,     0.95701,      0.9512,      0.9325,     0.90782,     0.81153,     0.59497,     0.20694],\n",
            "       [    0.79857,     0.78462,     0.75438,     0.68055,     0.61336,     0.50403,     0.39349,     0.22989,    0.088073,    0.011263],\n",
            "       [    0.68176,     0.65881,     0.65881,     0.64834,     0.64834,     0.59738,     0.37054,     0.23738,    0.024963,           0],\n",
            "       [    0.86203,     0.85101,     0.84098,     0.81965,      0.7639,     0.70355,     0.55639,     0.44354,      0.2316,   0.0090597],\n",
            "       [    0.92864,     0.92864,     0.91393,     0.84355,     0.84218,     0.77381,     0.72341,     0.67603,     0.46652,     0.20041],\n",
            "       [    0.87083,     0.87083,     0.86461,      0.8334,     0.80112,     0.71506,     0.61137,     0.54908,     0.35098,     0.18487],\n",
            "       [    0.33237,     0.29469,      0.2495,     0.20262,     0.14514,    0.099413,    0.056202,    0.023579,    0.003589,           0]])\n",
            "ap: array([    0.80247,      0.7683,     0.82437,     0.48582,     0.45263,     0.60817,     0.72971,     0.66521,     0.14071])\n",
            "ap50: array([    0.95535,     0.93545,     0.96233,     0.79857,     0.68176,     0.86203,     0.92864,     0.87083,     0.33237])\n",
            "ap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
            "curves: []\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.026269,    0.013135,           0],\n",
            "       [          1,           1,           1, ...,    0.017893,   0.0089463,           0],\n",
            "       [          1,           1,           1, ...,    0.031783,    0.015891,           0],\n",
            "       ...,\n",
            "       [          1,           1,           1, ...,    0.018747,   0.0093733,           0],\n",
            "       [          1,           1,           1, ...,   0.0086199,   0.0043099,           0],\n",
            "       [    0.81818,     0.81818,     0.81818, ...,   0.0012618,   0.0006309,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.90167,     0.90167,     0.90167, ...,           0,           0,           0],\n",
            "       [    0.87439,     0.87439,     0.87439, ...,           0,           0,           0],\n",
            "       [    0.92891,     0.92891,     0.92891, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.87179,     0.87179,     0.87179, ...,           0,           0,           0],\n",
            "       [    0.80874,     0.80874,     0.80874, ...,           0,           0,           0],\n",
            "       [    0.31239,     0.31239,     0.31239, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.87189,     0.87189,     0.87189, ...,           1,           1,           1],\n",
            "       [    0.84543,     0.84543,     0.84543, ...,           1,           1,           1],\n",
            "       [    0.91589,     0.91589,     0.91589, ...,           1,           1,           1],\n",
            "       ...,\n",
            "       [    0.83607,     0.83607,     0.83607, ...,           1,           1,           1],\n",
            "       [    0.80435,     0.80435,     0.80435, ...,           1,           1,           1],\n",
            "       [    0.48506,     0.48506,     0.48506, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.93355,     0.93355,     0.93355, ...,           0,           0,           0],\n",
            "       [    0.90541,     0.90541,     0.90541, ...,           0,           0,           0],\n",
            "       [    0.94231,     0.94231,     0.94231, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.91071,     0.91071,     0.91071, ...,           0,           0,           0],\n",
            "       [    0.81319,     0.81319,     0.81319, ...,           0,           0,           0],\n",
            "       [    0.23038,     0.23038,     0.23038, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "f1: array([    0.90167,     0.87439,     0.92891,     0.73394,     0.65385,     0.78963,     0.87179,     0.80874,     0.31239])\n",
            "f1_curve: array([[    0.90167,     0.90167,     0.90167, ...,           0,           0,           0],\n",
            "       [    0.87439,     0.87439,     0.87439, ...,           0,           0,           0],\n",
            "       [    0.92891,     0.92891,     0.92891, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.87179,     0.87179,     0.87179, ...,           0,           0,           0],\n",
            "       [    0.80874,     0.80874,     0.80874, ...,           0,           0,           0],\n",
            "       [    0.31239,     0.31239,     0.31239, ...,           0,           0,           0]])\n",
            "map: 0.6086004019658381\n",
            "map50: 0.8141488421254083\n",
            "map75: 0.6792187966882\n",
            "maps: array([    0.80247,      0.7683,     0.82437,     0.48582,     0.45263,     0.60817,     0.72971,     0.66521,     0.14071])\n",
            "mp: 0.7691860634455633\n",
            "mr: 0.769836745120831\n",
            "nc: 9\n",
            "p: array([    0.87189,     0.84543,     0.91589,     0.74246,     0.62963,     0.79191,     0.83607,     0.80435,     0.48506])\n",
            "p_curve: array([[    0.87189,     0.87189,     0.87189, ...,           1,           1,           1],\n",
            "       [    0.84543,     0.84543,     0.84543, ...,           1,           1,           1],\n",
            "       [    0.91589,     0.91589,     0.91589, ...,           1,           1,           1],\n",
            "       ...,\n",
            "       [    0.83607,     0.83607,     0.83607, ...,           1,           1,           1],\n",
            "       [    0.80435,     0.80435,     0.80435, ...,           1,           1,           1],\n",
            "       [    0.48506,     0.48506,     0.48506, ...,           1,           1,           1]])\n",
            "prec_values: array([[          1,           1,           1, ...,    0.026269,    0.013135,           0],\n",
            "       [          1,           1,           1, ...,    0.017893,   0.0089463,           0],\n",
            "       [          1,           1,           1, ...,    0.031783,    0.015891,           0],\n",
            "       ...,\n",
            "       [          1,           1,           1, ...,    0.018747,   0.0093733,           0],\n",
            "       [          1,           1,           1, ...,   0.0086199,   0.0043099,           0],\n",
            "       [    0.81818,     0.81818,     0.81818, ...,   0.0012618,   0.0006309,           0]])\n",
            "px: array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1])\n",
            "r: array([    0.93355,     0.90541,     0.94231,     0.72562,        0.68,     0.78736,     0.91071,     0.81319,     0.23038])\n",
            "r_curve: array([[    0.93355,     0.93355,     0.93355, ...,           0,           0,           0],\n",
            "       [    0.90541,     0.90541,     0.90541, ...,           0,           0,           0],\n",
            "       [    0.94231,     0.94231,     0.94231, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.91071,     0.91071,     0.91071, ...,           0,           0,           0],\n",
            "       [    0.81319,     0.81319,     0.81319, ...,           0,           0,           0],\n",
            "       [    0.23038,     0.23038,     0.23038, ...,           0,           0,           0]])\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ ... ]]\n",
            "Precision: 0.77\n",
            "Recall: 0.77\n",
            "F1 Score: 0.77\n",
            "mAP@50: 0.81\n",
            "mAP@50:95: Not Available\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (50,) and (2,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6197545b95d5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mAP@50:95'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"green\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mAP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (2,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the path to the best weights\n",
        "best_weights_path = f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/best.pt'\n",
        "\n",
        "# Initialize YOLOv8 model with the best weights\n",
        "model = YOLO(best_weights_path).to(device)\n",
        "\n",
        "# Perform validation\n",
        "validation_results = model.val(\n",
        "    data=DATA_CONFIG,\n",
        "    split='val',\n",
        "    conf=CONFIDENCE_THRESHOLD,\n",
        "    save=False,\n",
        "    plots=False\n",
        ")\n",
        "\n",
        "print(\"\\nValidation completed!\\n\")\n",
        "\n",
        "# The result from model.val() is a 'DetMetrics' object that summarizes performance.\n",
        "# Let's inspect the validation results object for metrics\n",
        "\n",
        "print(\"Validation Results (raw DetMetrics object):\")\n",
        "print(validation_results)\n",
        "\n",
        "# Access relevant metrics from the DetMetrics object\n",
        "metrics = validation_results.box  # box is an instance of the Metric class storing results for boxes\n",
        "print(\"\\nBox Metrics:\")\n",
        "print(metrics)\n",
        "\n",
        "# The metrics object holds various metrics like mAP, precision, recall, etc.\n",
        "# Extract relevant values:\n",
        "precision = getattr(metrics, 'mp', None)  # mean precision\n",
        "recall = getattr(metrics, 'mr', None)  # mean recall\n",
        "map_50 = getattr(metrics, 'map50', None)  # mean average precision at IoU=0.50\n",
        "map_50_95 = getattr(metrics, 'map50_95', None)  # mean average precision at IoU=0.50:0.95\n",
        "\n",
        "# Calculate F1 score if precision and recall are available\n",
        "f1_score = None\n",
        "if precision is not None and recall is not None and (precision + recall) > 0:\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Placeholder for confusion matrix (optional implementation)\n",
        "confusion_matrix = None\n",
        "\n",
        "# Print metrics in the requested format\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "if confusion_matrix is not None:\n",
        "    print(confusion_matrix)\n",
        "else:\n",
        "    print(\"[[ ... ]]\")  # Placeholder for an actual confusion matrix if implemented\n",
        "\n",
        "if precision is not None:\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "else:\n",
        "    print(\"Precision: Not Available\")\n",
        "\n",
        "if recall is not None:\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "else:\n",
        "    print(\"Recall: Not Available\")\n",
        "\n",
        "if f1_score is not None:\n",
        "    print(f\"F1 Score: {f1_score:.2f}\")\n",
        "else:\n",
        "    print(\"F1 Score: Not Available\")\n",
        "\n",
        "if map_50 is not None:\n",
        "    print(f\"mAP@50: {map_50:.2f}\")\n",
        "else:\n",
        "    print(\"mAP@50: Not Available\")\n",
        "\n",
        "if map_50_95 is not None:\n",
        "    print(f\"mAP@50:95: {map_50_95:.2f}\")\n",
        "else:\n",
        "    print(\"mAP@50:95: Not Available\")\n",
        "\n",
        "# ----------- Plotting Precision-Recall Curve -----------\n",
        "\n",
        "# Assuming precision and recall are arrays (e.g., from 'validation_results' or from 'metrics')\n",
        "if precision is not None and recall is not None:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(recall, precision, label=\"Precision-Recall curve\", color=\"blue\", lw=2)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# ----------- Plotting mAP vs Epochs -----------\n",
        "\n",
        "# Assuming you have stored mAP values during training and validation across epochs\n",
        "epochs = list(range(1, EPOCHS+1))\n",
        "map_values = [map_50, map_50_95]  # Example for plotting mAP over epochs\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, map_values, label='mAP@50:95', color=\"green\", lw=2)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('mAP')\n",
        "plt.title('mAP vs Epochs')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmZhL7O8YsdH"
      },
      "source": [
        "# 8. Predictions on Validation Set (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd0HyT7lYsdH"
      },
      "outputs": [],
      "source": [
        "val_predictions = model.predict(\n",
        "    source=str((VALID_DIR).resolve()),\n",
        "    save=True,\n",
        "    conf=CONFIDENCE_THRESHOLD\n",
        ")\n",
        "\n",
        "if val_predictions:\n",
        "    predictions_save_dir = val_predictions[0].save_dir\n",
        "    print(f\"\\nPredictions saved to '{predictions_save_dir}'.\\n\")\n",
        "else:\n",
        "    print(\"No predictions were made.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiengQi7uLhN"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3oybidjHhP6"
      },
      "source": [
        "# object detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVYdC-yUHAcF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "\n",
        "# Define the directory where the predictions are saved\n",
        "prediction_dir = 'runs/detect/predict'\n",
        "\n",
        "# List all images in the prediction directory\n",
        "images = os.listdir(prediction_dir)\n",
        "\n",
        "# Display up to 10 images with predictions\n",
        "num_images_to_display = min(10, len(images))  # Ensure we don't exceed the number of available images\n",
        "fig, axes = plt.subplots(1, num_images_to_display, figsize=(200, 100))  # Create a row of subplots\n",
        "\n",
        "for i in range(num_images_to_display):\n",
        "    img_path = os.path.join(prediction_dir, images[i])  # Get image path\n",
        "    img = mpimg.imread(img_path)  # Load the image\n",
        "    axes[i].imshow(img)  # Show image on the corresponding subplot\n",
        "    axes[i].axis('off')  # Disable axis for the subplot\n",
        "\n",
        "plt.tight_layout()  # Adjust spacing between images\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSlGCa-Kvbgx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ufji5EqgqvNS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.spatial.distance import euclidean\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load YOLOv5 model (using YOLOv5s as specified)\n",
        "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Placeholder for a depth estimation model\n",
        "class DepthEstimationModel:\n",
        "    def predict(self, image):\n",
        "        \"\"\"\n",
        "        Generate a simulated depth map (replace with an actual depth estimation model if available).\n",
        "        \"\"\"\n",
        "        h, w = image.shape[:2]\n",
        "        depth_map = np.linspace(30, 80, w).reshape(1, -1).repeat(h, axis=0)  # Depth gradient from 30m to 80m\n",
        "        return depth_map\n",
        "\n",
        "depth_model = DepthEstimationModel()\n",
        "\n",
        "def estimate_distances_kitti(prediction_dir, output_dir, num_images_to_display=5):\n",
        "    \"\"\"\n",
        "    Function to calculate distances between detected vehicles in KITTI dataset images,\n",
        "    annotate them, and save the results in a new directory.\n",
        "\n",
        "    Args:\n",
        "        prediction_dir (str): Directory containing the KITTI images with detected objects.\n",
        "        output_dir (str): Directory to save annotated images with distance information.\n",
        "        num_images_to_display (int): Number of images to display with distance annotations.\n",
        "\n",
        "    Returns:\n",
        "        list: Distances between objects for each image.\n",
        "    \"\"\"\n",
        "    # Ensure prediction directory exists\n",
        "    if not os.path.exists(prediction_dir):\n",
        "        raise ValueError(f\"Directory '{prediction_dir}' does not exist!\")\n",
        "\n",
        "    images = [img for img in os.listdir(prediction_dir) if img.endswith(('png', 'jpg', 'jpeg'))]\n",
        "    if not images:\n",
        "        raise ValueError(f\"No image files found in directory '{prediction_dir}'!\")\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    all_distances = []  # Store distances for all images\n",
        "    num_images_to_display = min(num_images_to_display, len(images))  # Limit images to display\n",
        "    fig, axes = plt.subplots(1, num_images_to_display, figsize=(20, 10))\n",
        "\n",
        "    for i, img_file in enumerate(images):\n",
        "        img_path = os.path.join(prediction_dir, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not load image at path '{img_path}'. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Perform object detection\n",
        "        results = yolo_model(img_rgb)\n",
        "        detections = results.xyxy[0].cpu().numpy()\n",
        "\n",
        "        # Filter for vehicles (car=2, motorcycle=3, bus=5, truck=7)\n",
        "        vehicle_detections = [d for d in detections if int(d[5]) in [2, 3, 5, 7]]\n",
        "\n",
        "        # Generate depth map\n",
        "        depth_map = depth_model.predict(img_rgb)\n",
        "\n",
        "        # Annotate image and calculate distances\n",
        "        distances = []\n",
        "        vehicle_centroids = []\n",
        "        for det in vehicle_detections:\n",
        "            x1, y1, x2, y2, conf, cls = map(int, det[:6])\n",
        "            vehicle_depth = depth_map[y1:y2, x1:x2].mean()  # Average depth within the bounding box\n",
        "            centroid = ((x1 + x2) // 2, (y1 + y2) // 2, vehicle_depth)\n",
        "            vehicle_centroids.append(centroid)\n",
        "\n",
        "            # Draw bounding box and label\n",
        "            label = f\"{int(cls)}: {vehicle_depth:.1f}m\"\n",
        "            cv2.rectangle(img_rgb, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "            cv2.putText(img_rgb, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "\n",
        "        # Calculate pairwise distances between vehicles\n",
        "        for j in range(len(vehicle_centroids)):\n",
        "            for k in range(j + 1, len(vehicle_centroids)):\n",
        "                dist = euclidean(vehicle_centroids[j], vehicle_centroids[k])\n",
        "                distances.append(dist)\n",
        "\n",
        "        all_distances.append((img_file, distances))\n",
        "\n",
        "        # Save the annotated image\n",
        "        output_path = os.path.join(output_dir, img_file)\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        # Display the annotated image\n",
        "        if i < num_images_to_display:\n",
        "            axes[i].imshow(img_rgb)\n",
        "            axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return all_distances\n",
        "\n",
        "# Example usage\n",
        "prediction_dir = 'runs/detect/predict'  # Directory with detected images from KITTI dataset\n",
        "output_dir = 'runs/detect/distance_estimation'  # Directory to save annotated images\n",
        "distances = estimate_distances_kitti(prediction_dir, output_dir)\n",
        "\n",
        "# Print distances between objects for each image\n",
        "for img_file, dist in distances:\n",
        "    print(f\"Image: {img_file}, Distances: {dist}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EIVQzo8tl0V"
      },
      "outputs": [],
      "source": [
        "# After saving the annotated image, display them if needed\n",
        "def display_images_from_directory(output_dir, num_images_to_display=5):\n",
        "    \"\"\"\n",
        "    Function to display the saved annotated images from the output directory.\n",
        "\n",
        "    Args:\n",
        "        output_dir (str): Directory containing the annotated images.\n",
        "        num_images_to_display (int): Number of images to display.\n",
        "    \"\"\"\n",
        "    images = [img for img in os.listdir(output_dir) if img.endswith(('png', 'jpg', 'jpeg'))]\n",
        "    if len(images) == 0:\n",
        "        print(f\"No images found in output directory '{output_dir}'.\")\n",
        "        return\n",
        "\n",
        "    num_images_to_display = min(num_images_to_display, len(images))\n",
        "    fig, axes = plt.subplots(1, num_images_to_display, figsize=(200, 50))\n",
        "\n",
        "    for i, img_file in enumerate(images[:num_images_to_display]):\n",
        "        img_path = os.path.join(output_dir, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        axes[i].imshow(img_rgb)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage to display images after processing\n",
        "display_images_from_directory(output_dir, num_images_to_display=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-AVzj9zD3WB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 976194,
          "sourceId": 1650695,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30786,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}