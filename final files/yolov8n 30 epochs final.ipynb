{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: code to prevent run time disconnect\n",
        "\n",
        "# This code will keep the Colab runtime active by periodically sending a request to the server.\n",
        "\n",
        "import time\n",
        "import IPython\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        "function ClickConnect(){\n",
        "  console.log(\"Working\");\n",
        "  document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect,600)\n",
        "'''))\n",
        "\n",
        "print(\"Colab will remain active. Do not close this tab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "N6v90c5C7njC",
        "outputId": "aef6641f-95d6-48a1-9975-d9b3ae3c70d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "function ClickConnect(){\n",
              "  console.log(\"Working\");\n",
              "  document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}\n",
              "setInterval(ClickConnect,600)\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab will remain active. Do not close this tab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djni4GQlYsc_",
        "outputId": "9dad9bbb-2c0f-42ee-a052-1aefbcfb5bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/klemenko/kitti-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22.5G/22.5G [04:12<00:00, 95.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK./root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1\n",
        "# /content/labels_with_dont_care\n",
        "import kagglehub\n",
        "klemenko_kitti_dataset_path = kagglehub.dataset_download('klemenko/kitti-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ybuXWu-SsC6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca597fe-4226-4629-8525-5b1d422555d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "print(klemenko_kitti_dataset_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iXziIp4WYsdC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import YOLOv7 library\n",
        "import sys\n",
        "sys.path.append('yolov7')  # Add YOLOv7 to the path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsbdbb78YsdD"
      },
      "source": [
        "# 1. Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n0USoyjHYsdD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ffa43b-779c-4564-f559-62bf1ab5084b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "data.yaml content:\n",
            "{'train': '/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train', 'val': '/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid', 'nc': 9, 'names': ['Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare']}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# KITTI dataset configuration\n",
        "KITTI_BASE_DIR = '/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1'\n",
        "\"\"\"str: The base directory where the KITTI dataset is located.\"\"\"\n",
        "\n",
        "IMAGE_DIR = Path(KITTI_BASE_DIR) / 'data_object_image_2' / 'training' / 'image_2'\n",
        "\"\"\"Path: Directory containing KITTI training images.\"\"\"\n",
        "\n",
        "LABEL_DIR = Path(KITTI_BASE_DIR) / 'data_object_label_2' / 'training' / 'label_2'\n",
        "\"\"\"Path: Directory containing KITTI training labels.\"\"\"\n",
        "\n",
        "TRAIN_DIR = Path(KITTI_BASE_DIR)/'train'\n",
        "\"\"\"Path: Directory where training images and labels will be stored in YOLOv7 format.\"\"\"\n",
        "\n",
        "VALID_DIR = Path(KITTI_BASE_DIR)/'valid'\n",
        "\"\"\"Path: Directory where validation images and labels will be stored in YOLOv7 format.\"\"\"\n",
        "\n",
        "LABELS_DIR = Path(KITTI_BASE_DIR)/'labels_with_dont_care'\n",
        "\"\"\"Path: Directory where YOLOv7-formatted labels will be stored.\"\"\"\n",
        "\n",
        "CLASSES = [\n",
        "    'Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting',\n",
        "    'Cyclist', 'Tram', 'Misc', 'DontCare'\n",
        "]\n",
        "\"\"\"\n",
        "list of str: List of class names included in the KITTI dataset.\n",
        "'CLASSES' should reflect all possible object categories for detection.\n",
        "\"\"\"\n",
        "\n",
        "# YOLOv7 model configuration\n",
        "WEIGHTS = 'yolov7.pt'  # Pretrained weights for YOLOv7\n",
        "\"\"\"str: Path to the YOLOv7 pretrained weights file.\"\"\"\n",
        "\n",
        "EPOCHS = 50\n",
        "\"\"\"int: Number of epochs for training. Adjust this value based on dataset size and desired training time.\"\"\"\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\"\"\"int: Batch size used during training. Adjust based on GPU memory constraints.\"\"\"\n",
        "\n",
        "IMG_SIZE = 640\n",
        "\"\"\"int: The size (height and width) of the input images for the model.\"\"\"\n",
        "\n",
        "CONFIDENCE_THRESHOLD = 0.25\n",
        "\"\"\"float: The confidence threshold for predictions during validation and testing.\"\"\"\n",
        "\n",
        "PROJECT_NAME = 'YOLOv7-KITTI'\n",
        "\"\"\"str: The name of the project folder where YOLOv7 results will be saved.\"\"\"\n",
        "\n",
        "EXPERIMENT_NAME = 'exp1'\n",
        "\"\"\"str: The name of the experiment folder within the project directory to store this run's results.\"\"\"\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\"\"\"str: The device to use for training and inference, defaults to GPU if available.\"\"\"\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path for the data.yaml file for YOLOv7\n",
        "DATA_CONFIG_PATH = '/content/data.yaml'\n",
        "\n",
        "# Prepare the data.yaml file with necessary paths and class names for YOLOv7\n",
        "data_config = {\n",
        "    'train': str(Path(TRAIN_DIR).resolve()),\n",
        "    'val': str(Path(VALID_DIR).resolve()),\n",
        "    'nc': len(CLASSES),\n",
        "    'names': CLASSES\n",
        "}\n",
        "\n",
        "# Write the data.yaml configuration for YOLOv7\n",
        "with open(DATA_CONFIG_PATH, 'w', encoding='utf-8') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "# Print out the data.yaml content for verification\n",
        "print(f\"data.yaml content:\\n{data_config}\")\n",
        "\n",
        "# YOLOv7 Training Command\n",
        "# Modify this line to execute the YOLOv7 training\n",
        "os.system(f\"\"\"\n",
        "python train.py --weights {WEIGHTS} \\\n",
        "--cfg ./models/yolov7.yaml \\\n",
        "--data {DATA_CONFIG_PATH} \\\n",
        "--epochs {EPOCHS} \\\n",
        "--batch-size {BATCH_SIZE} \\\n",
        "--img-size {IMG_SIZE} \\\n",
        "--project {PROJECT_NAME} \\\n",
        "--name {EXPERIMENT_NAME} \\\n",
        "--device {device} \\\n",
        "--exist-ok\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfyFbuOlYsdE"
      },
      "source": [
        "# 2. Data Preparation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qVwHwhr1YsdE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "# Class names for KITTI dataset\n",
        "CLASSES = [\n",
        "    'Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting',\n",
        "    'Cyclist', 'Tram', 'Misc', 'DontCare'\n",
        "]\n",
        "\"\"\"\n",
        "List of class names included in the KITTI dataset.\n",
        "'CLASSES' should reflect all possible object categories for detection.\n",
        "\"\"\"\n",
        "\n",
        "CLAZZ_NUMBERS = {name: idx for idx, name in enumerate(CLASSES)}\n",
        "\"\"\"\n",
        "dict: A mapping from class names to numeric labels.\n",
        "The numeric labels are used by YOLO for class indices.\n",
        "\"\"\"\n",
        "\n",
        "def convert_bbox_to_yolo(bbox, size):\n",
        "    \"\"\"\n",
        "    Convert KITTI bounding box coordinates to YOLO format.\n",
        "\n",
        "    Args:\n",
        "        bbox (tuple of float): Bounding box coordinates in the format (left, right, top, bottom).\n",
        "        size (tuple of int): Image size as (width, height).\n",
        "\n",
        "    Returns:\n",
        "        tuple of float: YOLO-formatted bounding box as (x_center, y_center, width, height) normalized by image size.\n",
        "    \"\"\"\n",
        "    dw = 1.0 / size[0]\n",
        "    dh = 1.0 / size[1]\n",
        "    x_center = (bbox[0] + bbox[1]) / 2.0\n",
        "    y_center = (bbox[2] + bbox[3]) / 2.0\n",
        "    width = bbox[1] - bbox[0]\n",
        "    height = bbox[3] - bbox[2]\n",
        "    x_center *= dw\n",
        "    width *= dw\n",
        "    y_center *= dh\n",
        "    height *= dh\n",
        "    return x_center, y_center, width, height\n",
        "\n",
        "def parse_kitti_label_file(lbl_path, img_path):\n",
        "    \"\"\"\n",
        "    Parse a KITTI label file and convert the bounding boxes to YOLOv7 format.\n",
        "\n",
        "    Args:\n",
        "        lbl_path (Path): Path to the KITTI label file (in KITTI text format).\n",
        "        img_path (Path): Path to the corresponding image file.\n",
        "\n",
        "    Returns:\n",
        "        list of tuple: A list of YOLOv7-formatted bounding boxes. Each element is\n",
        "        (class_idx, x_center, y_center, width, height).\n",
        "    \"\"\"\n",
        "    with open(lbl_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.read().strip().split('\\n')\n",
        "\n",
        "    yolo_labels = []\n",
        "    if not img_path.exists():\n",
        "        # If the image doesn't exist, skip processing labels\n",
        "        return yolo_labels\n",
        "\n",
        "    img_size = Image.open(img_path).size  # (width, height)\n",
        "\n",
        "    for line in lines:\n",
        "        parts = line.split()\n",
        "        clazz = parts[0]\n",
        "        if clazz not in CLAZZ_NUMBERS:\n",
        "            # Skip classes not in our mapping\n",
        "            continue\n",
        "\n",
        "        # KITTI format:\n",
        "        # type, truncated, occluded, alpha, bbox_left, bbox_top, bbox_right, bbox_bottom, ...\n",
        "        # Indices:  0    ,    1     ,   2     ,   3  ,    4     ,    5    ,     6     ,      7    ...\n",
        "        # Example: Car 0.00 0 1.57 148.00 174.00 350.00 325.00 ...\n",
        "        # The bounding box coordinates: left = parts[4], top = parts[5], right = parts[6], bottom = parts[7]\n",
        "        bbox_left = float(parts[4])\n",
        "        bbox_top = float(parts[5])\n",
        "        bbox_right = float(parts[6])\n",
        "        bbox_bottom = float(parts[7])\n",
        "        bbox = (bbox_left, bbox_right, bbox_top, bbox_bottom)\n",
        "\n",
        "        # Convert bounding box to YOLO format (normalized)\n",
        "        x_center, y_center, width, height = convert_bbox_to_yolo(bbox, img_size)\n",
        "        clazz_number = CLAZZ_NUMBERS[clazz]\n",
        "\n",
        "        # YOLOv7 format: class x_center y_center width height\n",
        "        yolo_labels.append((clazz_number, x_center, y_center, width, height))\n",
        "\n",
        "    return yolo_labels\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvVH8XR0YsdF"
      },
      "source": [
        "# 3. Generate YOLO labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vHnBl36UYsdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a4827a-1f95-4e32-f9ac-188092c4504d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO format labels have been generated in: /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/labels_with_dont_care\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Check if the labels directory exists, create it if not\n",
        "if not LABELS_DIR.exists():\n",
        "    LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Sort image and label paths\n",
        "image_paths = sorted(list(IMAGE_DIR.glob('*.png')))\n",
        "label_paths = sorted(list(LABEL_DIR.glob('*.txt')))\n",
        "\n",
        "# Process each image and its corresponding label file\n",
        "for img_path in image_paths:\n",
        "    lbl_path = LABEL_DIR / f\"{img_path.stem}.txt\"\n",
        "\n",
        "    # Ensure that the label file exists\n",
        "    if lbl_path.exists():\n",
        "        # Parse KITTI label to YOLOv7 format\n",
        "        yolo_labels = parse_kitti_label_file(lbl_path, img_path)\n",
        "\n",
        "        # Define the output label file path\n",
        "        yolo_label_path = LABELS_DIR / f\"{img_path.stem}.txt\"\n",
        "\n",
        "        # Write the YOLOv7-formatted labels to the label file\n",
        "        with open(yolo_label_path, 'w', encoding='utf-8') as lf:\n",
        "            for lbl in yolo_labels:\n",
        "                # Write each label with 6 decimal places for each value\n",
        "                lf.write(\" \".join(f\"{val:.6f}\" for val in lbl) + \"\\n\")\n",
        "\n",
        "print(f\"YOLO format labels have been generated in: {LABELS_DIR.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNFi6m5CYsdF"
      },
      "source": [
        "# 4. Split Dataset into Train and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaBKKlXxYsdG",
        "outputId": "b5493576-9ae4-4cb3-91fa-cdd2a91b2329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 6732, Validation samples: 749\n",
            "Training data copied to /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train/images and /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train/labels\n",
            "Validation data copied to /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/images and /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/labels\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a list of image and label pairs for labels that exist in LABELS_DIR\n",
        "labels_for_images = [(img_path, LABELS_DIR / f\"{img_path.stem}.txt\")\n",
        "                     for img_path in image_paths\n",
        "                     if (LABELS_DIR / f\"{img_path.stem}.txt\").exists()]\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_pairs, valid_pairs = train_test_split(\n",
        "    labels_for_images,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Print the number of training and validation samples\n",
        "print(f\"Training samples: {len(train_pairs)}, Validation samples: {len(valid_pairs)}\")\n",
        "\n",
        "# Create directories for YOLOv7 data structure (images and labels)\n",
        "for folder in [TRAIN_DIR, VALID_DIR]:\n",
        "    if folder.exists():\n",
        "        shutil.rmtree(folder)  # Remove existing folder contents\n",
        "    folder.mkdir(parents=True, exist_ok=True)  # Create the folder\n",
        "    (folder / 'images').mkdir(parents=True, exist_ok=True)  # Create images subfolder\n",
        "    (folder / 'labels').mkdir(parents=True, exist_ok=True)  # Create labels subfolder\n",
        "\n",
        "# Copy images and labels to the training folder\n",
        "for img_path, lbl_path in train_pairs:\n",
        "    shutil.copy(img_path, TRAIN_DIR / 'images' / img_path.name)  # Copy image\n",
        "    shutil.copy(lbl_path, TRAIN_DIR / 'labels' / lbl_path.name)  # Copy label\n",
        "\n",
        "# Copy images and labels to the validation folder\n",
        "for img_path, lbl_path in valid_pairs:\n",
        "    shutil.copy(img_path, VALID_DIR / 'images' / img_path.name)  # Copy image\n",
        "    shutil.copy(lbl_path, VALID_DIR / 'labels' / lbl_path.name)  # Copy label\n",
        "\n",
        "# Print where the data is copied\n",
        "print(f\"Training data copied to {TRAIN_DIR / 'images'} and {TRAIN_DIR / 'labels'}\")\n",
        "print(f\"Validation data copied to {VALID_DIR / 'images'} and {VALID_DIR / 'labels'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAfxeiRtYsdG"
      },
      "source": [
        "# 5. Create data.yaml File for YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw4SxV1kEHQ8",
        "outputId": "7cbf3a84-2073-4698-c88e-0d3e29d382e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv7 data.yaml file created with content:\n",
            "{'train': '/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train/images', 'val': '/root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/images', 'nc': 9, 'names': ['Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare']}\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the class names for the KITTI dataset\n",
        "CLASSES = [\n",
        "    'Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting',\n",
        "    'Cyclist', 'Tram', 'Misc', 'DontCare'\n",
        "]\n",
        "\"\"\"\n",
        "list of str: List of class names in the KITTI dataset.\n",
        "\"\"\"\n",
        "\n",
        "# Define the directories for training and validation images\n",
        "TRAIN_IMAGES_DIR = Path(KITTI_BASE_DIR) / 'train' / 'images'\n",
        "VALID_IMAGES_DIR = Path(KITTI_BASE_DIR) / 'valid' / 'images'\n",
        "\n",
        "# Define the path for the data.yaml file\n",
        "YOLOV7_DATA_CONFIG_PATH = Path(KITTI_BASE_DIR) / 'yolov7_data.yaml'\n",
        "\n",
        "# Prepare the data configuration dictionary for YOLOv7\n",
        "yolov7_data_config = {\n",
        "    'train': str(TRAIN_IMAGES_DIR.resolve()),  # Absolute path to training images\n",
        "    'val': str(VALID_IMAGES_DIR.resolve()),   # Absolute path to validation images\n",
        "    'nc': len(CLASSES),                       # Number of classes\n",
        "    'names': CLASSES                          # List of class names\n",
        "}\n",
        "\n",
        "# Write the data configuration to the yolov7_data.yaml file\n",
        "with open(YOLOV7_DATA_CONFIG_PATH, 'w', encoding='utf-8') as f:\n",
        "    yaml.dump(yolov7_data_config, f, default_flow_style=False)\n",
        "\n",
        "# Output the content of the generated yolov7_data.yaml file\n",
        "print(\"YOLOv7 data.yaml file created with content:\")\n",
        "print(yolov7_data_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbYw3sSQ3Lco",
        "outputId": "41bf29c1-21c4-456e-e35b-89e6e433fe7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yolov8\n",
            "  Downloading yolov8-0.0.2-py37.py38.py39-none-any.whl.metadata (2.0 kB)\n",
            "Collecting yolov5 (from yolov8)\n",
            "  Downloading yolov5-7.0.14-py37.py38.py39.py310-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (3.1.44)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (11.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (1.13.1)\n",
            "Collecting thop>=0.1.1 (from yolov5->yolov8)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (4.67.1)\n",
            "Collecting ultralytics>=8.0.100 (from yolov5->yolov8)\n",
            "  Downloading ultralytics-8.3.63-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (2.17.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.11/dist-packages (from yolov5->yolov8) (75.1.0)\n",
            "Collecting fire (from yolov5->yolov8)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3>=1.19.1 (from yolov5->yolov8)\n",
            "  Downloading boto3-1.36.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sahi>=0.11.10 (from yolov5->yolov8)\n",
            "  Downloading sahi-0.11.20-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting huggingface-hub<0.25.0,>=0.12.0 (from yolov5->yolov8)\n",
            "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting roboflow>=0.2.29 (from yolov5->yolov8)\n",
            "  Downloading roboflow-1.1.51-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting botocore<1.37.0,>=1.36.2 (from boto3>=1.19.1->yolov5->yolov8)\n",
            "  Downloading botocore-1.36.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.19.1->yolov5->yolov8)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3>=1.19.1->yolov5->yolov8)\n",
            "  Downloading s3transfer-0.11.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->yolov5->yolov8) (4.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5->yolov8) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5->yolov8) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5->yolov8) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5->yolov8) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->yolov5->yolov8) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->yolov5->yolov8) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->yolov5->yolov8) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5->yolov8) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5->yolov8) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5->yolov8) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->yolov5->yolov8) (2024.12.14)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.23.0->yolov5->yolov8)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.29->yolov5->yolov8) (4.10.0.84)\n",
            "Collecting python-dotenv (from roboflow>=0.2.29->yolov5->yolov8)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.29->yolov5->yolov8) (1.17.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow>=0.2.29->yolov5->yolov8) (1.0.0)\n",
            "Collecting filetype (from roboflow>=0.2.29->yolov5->yolov8)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from sahi>=0.11.10->yolov5->yolov8) (2.0.6)\n",
            "Collecting pybboxes==0.1.6 (from sahi>=0.11.10->yolov5->yolov8)\n",
            "  Downloading pybboxes-0.1.6-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting terminaltables (from sahi>=0.11.10->yolov5->yolov8)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sahi>=0.11.10->yolov5->yolov8) (8.1.8)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (1.69.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (4.25.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->yolov5->yolov8) (3.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->yolov5->yolov8) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->yolov5->yolov8) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->yolov5->yolov8) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.0.100->yolov5->yolov8) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.0.100->yolov5->yolov8)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->yolov5->yolov8) (2.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->yolov5->yolov8) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->yolov5->yolov8) (3.0.2)\n",
            "Downloading yolov8-0.0.2-py37.py38.py39-none-any.whl (1.9 kB)\n",
            "Downloading yolov5-7.0.14-py37.py38.py39.py310-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.5/953.5 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.36.2-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roboflow-1.1.51-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sahi-0.11.20-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybboxes-0.1.6-py3-none-any.whl (24 kB)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading ultralytics-8.3.63-py3-none-any.whl (910 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m910.2/910.2 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.36.2-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=d7628baf5415b43765f3e1efbdfef0096b60fdc14b44bf5199817228f81c5cb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: filetype, terminaltables, python-dotenv, pybboxes, jmespath, idna, fire, botocore, sahi, s3transfer, huggingface-hub, ultralytics-thop, thop, roboflow, boto3, ultralytics, yolov5, yolov8\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.27.1\n",
            "    Uninstalling huggingface-hub-0.27.1:\n",
            "      Successfully uninstalled huggingface-hub-0.27.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.24.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed boto3-1.36.2 botocore-1.36.2 filetype-1.2.0 fire-0.7.0 huggingface-hub-0.24.7 idna-3.7 jmespath-1.0.1 pybboxes-0.1.6 python-dotenv-1.0.1 roboflow-1.1.51 s3transfer-0.11.1 sahi-0.11.20 terminaltables-3.1.10 thop-0.1.1.post2209072238 ultralytics-8.3.63 ultralytics-thop-2.0.14 yolov5-7.0.14 yolov8-0.0.2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install yolov8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0PyBFQxYsdG"
      },
      "source": [
        "# 6. Train the YOLO11 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBFYFegxZJgq"
      },
      "source": [
        "MODEL ARCHITECTURE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuE458F05bdO",
        "outputId": "60920956-f9bc-4538-817b-2b7d4c51ecf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.63)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Setup complete. Using torch 2.5.1+cu121 (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "# Install YOLOv8\n",
        "!pip install ultralytics  # Install the ultralytics library for YOLOv8\n",
        "\n",
        "# Import the library and check setup\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Print system and environment information\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lei-dUYfhiOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics -q"
      ],
      "metadata": {
        "id": "8Rq-HDXsusp-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import json\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm\n",
        "import shutil\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "0y5-WSb6uwFA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Define configuration\n",
        "MODEL_ARCH = 'yolov8n.pt'  # YOLOv8 Nano model (change to 'yolov8s.pt', 'yolov8m.pt', etc., for other versions)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Define the training parameters\n",
        "DATA_CONFIG = '/content/data.yaml'  # Path to the data.yaml file\n",
        "EPOCHS = 30  # Reduced epochs to 30 for faster training\n",
        "BATCH_SIZE = 16  # Batch size (adjust based on GPU resources)\n",
        "IMG_SIZE = 512  # Reduced image size to 512 for faster processing\n",
        "CONFIDENCE_THRESHOLD = 0.25  # Confidence threshold for validation\n",
        "\n",
        "PROJECT_NAME = 'YOLOv8-KITTI'  # Project folder name\n",
        "EXPERIMENT_NAME = 'exp1'  # Experiment name\n",
        "\n",
        "# Path to weights\n",
        "weights_dir = f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights'\n",
        "last_weights_path = os.path.join(weights_dir, 'last.pt')\n",
        "\n",
        "# Check if a checkpoint exists\n",
        "resume_training = os.path.exists(last_weights_path)\n",
        "\n",
        "# Initialize the model\n",
        "if resume_training:\n",
        "    print(f\"Resuming training from checkpoint: {last_weights_path}\")\n",
        "    model = YOLO(last_weights_path)  # Resume from the last checkpoint\n",
        "else:\n",
        "    print(f\"Starting fresh training with model: {MODEL_ARCH}\")\n",
        "    model = YOLO(MODEL_ARCH)  # Start fresh training\n",
        "\n",
        "# Train the model\n",
        "try:\n",
        "    train_results = model.train(\n",
        "        data=DATA_CONFIG,\n",
        "        epochs=EPOCHS,\n",
        "        batch=BATCH_SIZE,\n",
        "        imgsz=IMG_SIZE,\n",
        "        project=PROJECT_NAME,\n",
        "        name=EXPERIMENT_NAME,\n",
        "        device=device,\n",
        "        save_period=5,  # Save checkpoints every 5 epochs\n",
        "        exist_ok=True  # Avoid overwriting existing experiments\n",
        "    )\n",
        "    print(\"\\nTraining completed!\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nTraining interrupted due to: {e}\\n\")\n",
        "    print(\"Attempting to save progress...\")\n",
        "    # Save the current model state\n",
        "    if hasattr(model, 'save'):\n",
        "        model.save(last_weights_path)\n",
        "        print(f\"Progress saved at {last_weights_path}\")\n",
        "\n",
        "# Summary of training\n",
        "print(f\"Project directory: {PROJECT_NAME}/{EXPERIMENT_NAME}\")\n",
        "if resume_training:\n",
        "    print(f\"Resumed from checkpoint: {last_weights_path}\")\n",
        "else:\n",
        "    print(\"Training started from scratch.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwo012ohhm3p",
        "outputId": "fc7a3d8e-90b7-4a04-8bbc-218ec7ab163a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting fresh training with model: yolov8n.pt\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 106MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.63 🚀 Python-3.11.11 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=5, cache=False, device=cuda, workers=8, project=YOLOv8-KITTI, name=exp1, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=YOLOv8-KITTI/exp1\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 20.4MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=9\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,012,603 parameters, 3,012,587 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir YOLOv8-KITTI/exp1', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 76.7MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train/labels... 6732 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6732/6732 [00:39<00:00, 168.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/labels... 749 images, 0 backgrounds, 0 corrupt: 100%|██████████| 749/749 [00:05<00:00, 143.54it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/labels.cache\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to YOLOv8-KITTI/exp1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 512 train, 512 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mYOLOv8-KITTI/exp1\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/30      1.57G      1.566      1.946      1.094        245        512: 100%|██████████| 421/421 [02:46<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.435      0.301      0.288      0.164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/30       1.7G      1.428      1.256      1.061        158        512: 100%|██████████| 421/421 [02:42<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.13it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.349      0.363      0.354      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/30      1.53G      1.373       1.12      1.052        125        512: 100%|██████████| 421/421 [02:40<00:00,  2.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:12<00:00,  1.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.531      0.359      0.374      0.215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/30      1.59G      1.347       1.05      1.041        174        512: 100%|██████████| 421/421 [02:41<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.461      0.412      0.419      0.247\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/30      1.51G      1.304     0.9841      1.027        158        512: 100%|██████████| 421/421 [02:39<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.13it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.546      0.436       0.46      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/30      1.59G      1.276     0.9439      1.016        195        512: 100%|██████████| 421/421 [02:41<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.552      0.466      0.491      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/30      1.71G      1.262      0.914      1.014        196        512: 100%|██████████| 421/421 [02:41<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.634      0.468      0.526      0.315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/30      1.65G      1.236     0.8827      1.006        160        512: 100%|██████████| 421/421 [02:36<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.584      0.482      0.521      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/30      1.55G      1.219     0.8692      1.001        179        512: 100%|██████████| 421/421 [02:38<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.627      0.486      0.557      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/30      1.59G      1.204     0.8456     0.9949        201        512: 100%|██████████| 421/421 [02:39<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.658      0.491      0.556      0.341\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/30      1.79G      1.191     0.8309     0.9882        194        512: 100%|██████████| 421/421 [02:38<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.60it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.646      0.526       0.59      0.363\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/30      1.61G      1.174     0.8109     0.9857        138        512: 100%|██████████| 421/421 [02:39<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.662      0.535       0.59      0.367\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/30      1.57G      1.162     0.7986     0.9799        181        512: 100%|██████████| 421/421 [02:34<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.09it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.697      0.529      0.601      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/30       1.7G      1.147      0.779     0.9753        155        512: 100%|██████████| 421/421 [02:38<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.701      0.559      0.611      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/30      1.62G      1.138     0.7656     0.9717        107        512: 100%|██████████| 421/421 [02:32<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.607      0.561      0.614      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/30       1.5G       1.12     0.7527      0.966        153        512: 100%|██████████| 421/421 [02:31<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.05it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425       0.72      0.537      0.632      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/30      1.58G      1.115     0.7424     0.9677        175        512: 100%|██████████| 421/421 [02:31<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.12it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.672      0.574      0.627        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/30      1.45G      1.106     0.7349     0.9636        162        512: 100%|██████████| 421/421 [02:34<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.698      0.586       0.64      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/30      1.66G      1.099     0.7264     0.9596        199        512: 100%|██████████| 421/421 [02:32<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.729       0.59      0.656      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/30       1.5G      1.078     0.7119     0.9535        256        512: 100%|██████████| 421/421 [02:32<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:10<00:00,  2.34it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.817       0.55       0.66      0.425\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/30      1.37G      1.067     0.6864     0.9476         89        512: 100%|██████████| 421/421 [02:33<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.795      0.558      0.674      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/30      1.37G       1.05     0.6695     0.9423         71        512: 100%|██████████| 421/421 [02:30<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.702      0.598      0.668      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/30      1.37G      1.044     0.6604     0.9393        103        512: 100%|██████████| 421/421 [02:30<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.12it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.772      0.585      0.679      0.442\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/30      1.34G      1.023     0.6473     0.9352         91        512: 100%|██████████| 421/421 [02:32<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:11<00:00,  2.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425       0.73      0.616      0.689       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      25/30      1.36G      1.015     0.6415     0.9336         65        512: 100%|██████████| 421/421 [02:30<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.58it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.753      0.627      0.691      0.449\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      26/30      1.36G      1.007     0.6328     0.9296         83        512: 100%|██████████| 421/421 [02:30<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.53it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.741      0.657      0.696      0.453\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      27/30      1.37G     0.9911     0.6213     0.9244         80        512: 100%|██████████| 421/421 [02:28<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:09<00:00,  2.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        749       5425      0.705      0.662      0.705      0.462\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/30      1.36G     0.9826     0.6147     0.9208         67        512: 100%|██████████| 421/421 [02:32<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:08<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.741      0.663      0.714      0.467\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/30      1.36G     0.9762     0.6082     0.9185        101        512: 100%|██████████| 421/421 [02:28<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:14<00:00,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.758      0.644      0.715       0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/30      1.36G     0.9665     0.6015     0.9159         68        512: 100%|██████████| 421/421 [02:27<00:00,  2.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:08<00:00,  2.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425        0.8       0.64      0.719      0.473\n",
            "\n",
            "30 epochs completed in 1.401 hours.\n",
            "Optimizer stripped from YOLOv8-KITTI/exp1/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from YOLOv8-KITTI/exp1/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating YOLOv8-KITTI/exp1/weights/best.pt...\n",
            "Ultralytics 8.3.63 🚀 Python-3.11.11 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:13<00:00,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.786      0.645       0.72      0.473\n",
            "                   Car        678       3040      0.891      0.864      0.931      0.705\n",
            "                   Van        223        296      0.831      0.757      0.836      0.608\n",
            "                 Truck        102        104      0.918      0.885      0.921      0.712\n",
            "            Pedestrian        179        441      0.776      0.576      0.679      0.374\n",
            "        Person_sitting         12         25      0.547       0.64      0.614      0.308\n",
            "               Cyclist        124        174      0.864      0.603       0.71      0.414\n",
            "                  Tram         29         56      0.859      0.857      0.923      0.612\n",
            "                  Misc         75         91      0.774      0.565      0.684      0.473\n",
            "              DontCare        567       1198      0.617     0.0543      0.186     0.0532\n",
            "Speed: 0.1ms preprocess, 1.2ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1mYOLOv8-KITTI/exp1\u001b[0m\n",
            "\n",
            "Training completed!\n",
            "\n",
            "Project directory: YOLOv8-KITTI/exp1\n",
            "Training started from scratch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMc_KA_dYsdG"
      },
      "source": [
        "# 7. Validate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xav_3j84YsdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99da8d55-b6d9-43ed-88a1-74fd8b052672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary (fused): 168 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/.cache/kagglehub/datasets/klemenko/kitti-dataset/versions/1/valid/labels.cache... 749 images, 0 backgrounds, 0 corrupt: 100%|██████████| 749/749 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:12<00:00,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        749       5425      0.715      0.687      0.749      0.527\n",
            "                   Car        678       3040      0.834      0.887      0.924      0.743\n",
            "                   Van        223        296      0.773       0.77      0.839      0.665\n",
            "                 Truck        102        104      0.893      0.885      0.927      0.752\n",
            "            Pedestrian        179        441      0.684      0.628      0.722      0.441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Person_sitting         12         25      0.487       0.76      0.639       0.34\n",
            "               Cyclist        124        174      0.796      0.649      0.768        0.5\n",
            "                  Tram         29         56      0.781      0.893       0.92      0.644\n",
            "                  Misc         75         91      0.733      0.604      0.728      0.553\n",
            "              DontCare        567       1198       0.45      0.105      0.273      0.101\n",
            "Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "\n",
            "Validation completed!\n",
            "\n",
            "Validation Results (raw DetMetrics object):\n",
            "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
            "\n",
            "ap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
            "box: ultralytics.utils.metrics.Metric object\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f724ab71050>\n",
            "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.014719,   0.0073594,           0],\n",
            "       [          1,           1,           1, ...,   0.0067353,   0.0033677,           0],\n",
            "       [          1,           1,           1, ...,    0.015498,   0.0077488,           0],\n",
            "       ...,\n",
            "       [          1,           1,           1, ...,    0.014598,    0.007299,           0],\n",
            "       [          1,           1,           1, ...,   0.0037111,   0.0018556,           0],\n",
            "       [          1,           1,           1, ...,   0.0010068,   0.0005034,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.85965,     0.85965,     0.85965, ...,           0,           0,           0],\n",
            "       [    0.77157,     0.77157,     0.77157, ...,           0,           0,           0],\n",
            "       [    0.88889,     0.88889,     0.88889, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.83333,     0.83333,     0.83333, ...,           0,           0,           0],\n",
            "       [    0.66265,     0.66265,     0.66265, ...,           0,           0,           0],\n",
            "       [     0.1705,      0.1705,      0.1705, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.83437,     0.83437,     0.83437, ...,           1,           1,           1],\n",
            "       [    0.77288,     0.77288,     0.77288, ...,           1,           1,           1],\n",
            "       [     0.8932,      0.8932,      0.8932, ...,           1,           1,           1],\n",
            "       ...,\n",
            "       [    0.78125,     0.78125,     0.78125, ...,           1,           1,           1],\n",
            "       [    0.73333,     0.73333,     0.73333, ...,           1,           1,           1],\n",
            "       [       0.45,        0.45,        0.45, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.88651,     0.88651,     0.88651, ...,           0,           0,           0],\n",
            "       [    0.77027,     0.77027,     0.77027, ...,           0,           0,           0],\n",
            "       [    0.88462,     0.88462,     0.88462, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.89286,     0.89286,     0.89286, ...,           0,           0,           0],\n",
            "       [     0.6044,      0.6044,      0.6044, ...,           0,           0,           0],\n",
            "       [    0.10518,     0.10518,     0.10518, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "fitness: 0.54882981170848\n",
            "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
            "maps: array([    0.74336,     0.66484,     0.75244,     0.44086,     0.33985,     0.49995,     0.64373,     0.55295,      0.1015])\n",
            "names: {0: 'Car', 1: 'Van', 2: 'Truck', 3: 'Pedestrian', 4: 'Person_sitting', 5: 'Cyclist', 6: 'Tram', 7: 'Misc', 8: 'DontCare'}\n",
            "plot: False\n",
            "results_dict: {'metrics/precision(B)': 0.7146598500209826, 'metrics/recall(B)': 0.6868188948194722, 'metrics/mAP50(B)': 0.7488246552999758, 'metrics/mAP50-95(B)': 0.526608162420536, 'fitness': 0.54882981170848}\n",
            "save_dir: PosixPath('runs/detect/val2')\n",
            "speed: {'preprocess': 0.09218077156667875, 'inference': 1.7361319431157232, 'loss': 0.0007267151082628401, 'postprocess': 2.1940369472325405}\n",
            "task: 'detect'\n",
            "\n",
            "Box Metrics:\n",
            "ultralytics.utils.metrics.Metric object with attributes:\n",
            "\n",
            "all_ap: array([[    0.92383,     0.92038,     0.91209,     0.90088,      0.8818,     0.84862,     0.78346,      0.6788,     0.46797,     0.11583],\n",
            "       [    0.83945,     0.83261,     0.83261,      0.8227,     0.81047,     0.78745,     0.69055,     0.55473,     0.38258,    0.095272],\n",
            "       [    0.92715,     0.92715,     0.92715,     0.92715,     0.91573,     0.91028,     0.85417,      0.6291,     0.42356,    0.082969],\n",
            "       [    0.72201,     0.70224,     0.68256,      0.6392,     0.57637,        0.46,     0.35836,     0.19103,    0.071349,   0.0055106],\n",
            "       [    0.63875,     0.55587,     0.54139,     0.48129,     0.46053,      0.3313,     0.29812,    0.048846,    0.021186,    0.021186],\n",
            "       [    0.76766,     0.74729,     0.73643,     0.72536,     0.66469,     0.58045,     0.41225,     0.26734,     0.09399,   0.0040061],\n",
            "       [    0.91984,     0.89782,     0.86478,     0.79932,     0.76327,       0.694,     0.60135,     0.48502,     0.27779,     0.13405],\n",
            "       [    0.72822,     0.72822,     0.71193,     0.68678,     0.65675,     0.60481,     0.57996,     0.43769,     0.31983,    0.075277],\n",
            "       [     0.2725,     0.23421,     0.18462,     0.13098,    0.096541,    0.055433,    0.025821,    0.012818,   0.0020325,           0]])\n",
            "ap: array([    0.74336,     0.66484,     0.75244,     0.44086,     0.33985,     0.49995,     0.64373,     0.55295,      0.1015])\n",
            "ap50: array([    0.92383,     0.83945,     0.92715,     0.72201,     0.63875,     0.76766,     0.91984,     0.72822,      0.2725])\n",
            "ap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
            "curves: []\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.014719,   0.0073594,           0],\n",
            "       [          1,           1,           1, ...,   0.0067353,   0.0033677,           0],\n",
            "       [          1,           1,           1, ...,    0.015498,   0.0077488,           0],\n",
            "       ...,\n",
            "       [          1,           1,           1, ...,    0.014598,    0.007299,           0],\n",
            "       [          1,           1,           1, ...,   0.0037111,   0.0018556,           0],\n",
            "       [          1,           1,           1, ...,   0.0010068,   0.0005034,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.85965,     0.85965,     0.85965, ...,           0,           0,           0],\n",
            "       [    0.77157,     0.77157,     0.77157, ...,           0,           0,           0],\n",
            "       [    0.88889,     0.88889,     0.88889, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.83333,     0.83333,     0.83333, ...,           0,           0,           0],\n",
            "       [    0.66265,     0.66265,     0.66265, ...,           0,           0,           0],\n",
            "       [     0.1705,      0.1705,      0.1705, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.83437,     0.83437,     0.83437, ...,           1,           1,           1],\n",
            "       [    0.77288,     0.77288,     0.77288, ...,           1,           1,           1],\n",
            "       [     0.8932,      0.8932,      0.8932, ...,           1,           1,           1],\n",
            "       ...,\n",
            "       [    0.78125,     0.78125,     0.78125, ...,           1,           1,           1],\n",
            "       [    0.73333,     0.73333,     0.73333, ...,           1,           1,           1],\n",
            "       [       0.45,        0.45,        0.45, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.88651,     0.88651,     0.88651, ...,           0,           0,           0],\n",
            "       [    0.77027,     0.77027,     0.77027, ...,           0,           0,           0],\n",
            "       [    0.88462,     0.88462,     0.88462, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.89286,     0.89286,     0.89286, ...,           0,           0,           0],\n",
            "       [     0.6044,      0.6044,      0.6044, ...,           0,           0,           0],\n",
            "       [    0.10518,     0.10518,     0.10518, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "f1: array([    0.85965,     0.77157,     0.88889,     0.65485,     0.59375,     0.71519,     0.83333,     0.66265,      0.1705])\n",
            "f1_curve: array([[    0.85965,     0.85965,     0.85965, ...,           0,           0,           0],\n",
            "       [    0.77157,     0.77157,     0.77157, ...,           0,           0,           0],\n",
            "       [    0.88889,     0.88889,     0.88889, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.83333,     0.83333,     0.83333, ...,           0,           0,           0],\n",
            "       [    0.66265,     0.66265,     0.66265, ...,           0,           0,           0],\n",
            "       [     0.1705,      0.1705,      0.1705, ...,           0,           0,           0]])\n",
            "map: 0.526608162420536\n",
            "map50: 0.7488246552999758\n",
            "map75: 0.5858155579077019\n",
            "maps: array([    0.74336,     0.66484,     0.75244,     0.44086,     0.33985,     0.49995,     0.64373,     0.55295,      0.1015])\n",
            "mp: 0.7146598500209826\n",
            "mr: 0.6868188948194722\n",
            "nc: 9\n",
            "p: array([    0.83437,     0.77288,      0.8932,     0.68395,     0.48718,     0.79577,     0.78125,     0.73333,        0.45])\n",
            "p_curve: array([[    0.83437,     0.83437,     0.83437, ...,           1,           1,           1],\n",
            "       [    0.77288,     0.77288,     0.77288, ...,           1,           1,           1],\n",
            "       [     0.8932,      0.8932,      0.8932, ...,           1,           1,           1],\n",
            "       ...,\n",
            "       [    0.78125,     0.78125,     0.78125, ...,           1,           1,           1],\n",
            "       [    0.73333,     0.73333,     0.73333, ...,           1,           1,           1],\n",
            "       [       0.45,        0.45,        0.45, ...,           1,           1,           1]])\n",
            "prec_values: array([[          1,           1,           1, ...,    0.014719,   0.0073594,           0],\n",
            "       [          1,           1,           1, ...,   0.0067353,   0.0033677,           0],\n",
            "       [          1,           1,           1, ...,    0.015498,   0.0077488,           0],\n",
            "       ...,\n",
            "       [          1,           1,           1, ...,    0.014598,    0.007299,           0],\n",
            "       [          1,           1,           1, ...,   0.0037111,   0.0018556,           0],\n",
            "       [          1,           1,           1, ...,   0.0010068,   0.0005034,           0]])\n",
            "px: array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1])\n",
            "r: array([    0.88651,     0.77027,     0.88462,     0.62812,        0.76,     0.64943,     0.89286,      0.6044,     0.10518])\n",
            "r_curve: array([[    0.88651,     0.88651,     0.88651, ...,           0,           0,           0],\n",
            "       [    0.77027,     0.77027,     0.77027, ...,           0,           0,           0],\n",
            "       [    0.88462,     0.88462,     0.88462, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.89286,     0.89286,     0.89286, ...,           0,           0,           0],\n",
            "       [     0.6044,      0.6044,      0.6044, ...,           0,           0,           0],\n",
            "       [    0.10518,     0.10518,     0.10518, ...,           0,           0,           0]])\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ ... ]]\n",
            "Precision: 0.71\n",
            "Recall: 0.69\n",
            "F1 Score: 0.70\n",
            "mAP@50: 0.75\n",
            "mAP@50:95: Not Available\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the path to the best weights\n",
        "best_weights_path = f'{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/best.pt'\n",
        "\n",
        "# Initialize YOLOv5l model with the best weights\n",
        "model = YOLO(best_weights_path).to(device)\n",
        "\n",
        "# Perform validation\n",
        "validation_results = model.val(\n",
        "    data=DATA_CONFIG,\n",
        "    conf=CONFIDENCE_THRESHOLD,\n",
        "    save=False,\n",
        "    plots=False\n",
        ")\n",
        "\n",
        "print(\"\\nValidation completed!\\n\")\n",
        "\n",
        "# The result from model.val() is a 'DetMetrics' object that summarizes performance.\n",
        "# Let's inspect the validation results object for metrics\n",
        "\n",
        "print(\"Validation Results (raw DetMetrics object):\")\n",
        "print(validation_results)\n",
        "\n",
        "# Access relevant metrics from the DetMetrics object\n",
        "metrics = validation_results.box  # box is an instance of the Metric class storing results for boxes\n",
        "print(\"\\nBox Metrics:\")\n",
        "print(metrics)\n",
        "\n",
        "# The metrics object holds various metrics like mAP, precision, recall, etc.\n",
        "# Extract relevant values:\n",
        "precision = getattr(metrics, 'mp', None)  # mean precision\n",
        "recall = getattr(metrics, 'mr', None)  # mean recall\n",
        "map_50 = getattr(metrics, 'map50', None)  # mean average precision at IoU=0.50\n",
        "map_50_95 = getattr(metrics, 'map50_95', None)  # mean average precision at IoU=0.50:0.95\n",
        "\n",
        "# Calculate F1 score if precision and recall are available\n",
        "f1_score = None\n",
        "if precision is not None and recall is not None and (precision + recall) > 0:\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Placeholder for confusion matrix (optional implementation)\n",
        "confusion_matrix = None\n",
        "\n",
        "# Print metrics in the requested format\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "if confusion_matrix is not None:\n",
        "    print(confusion_matrix)\n",
        "else:\n",
        "    print(\"[[ ... ]]\")  # Placeholder for an actual confusion matrix if implemented\n",
        "\n",
        "if precision is not None:\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "else:\n",
        "    print(\"Precision: Not Available\")\n",
        "\n",
        "if recall is not None:\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "else:\n",
        "    print(\"Recall: Not Available\")\n",
        "\n",
        "if f1_score is not None:\n",
        "    print(f\"F1 Score: {f1_score:.2f}\")\n",
        "else:\n",
        "    print(\"F1 Score: Not Available\")\n",
        "\n",
        "if map_50 is not None:\n",
        "    print(f\"mAP@50: {map_50:.2f}\")\n",
        "else:\n",
        "    print(\"mAP@50: Not Available\")\n",
        "\n",
        "if map_50_95 is not None:\n",
        "    print(f\"mAP@50:95: {map_50_95:.2f}\")\n",
        "else:\n",
        "    print(\"mAP@50:95: Not Available\")\n",
        "\n",
        "# ----------- Plotting Precision-Recall Curve -----------\n",
        "\n",
        "# Assuming precision and recall are arrays (e.g., from 'validation_results' or from 'metrics')\n",
        "if precision is not None and recall is not None:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(recall, precision, label=\"Precision-Recall curve\", color=\"blue\", lw=2)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmZhL7O8YsdH"
      },
      "source": [
        "# 8. Predictions on Validation Set (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd0HyT7lYsdH"
      },
      "outputs": [],
      "source": [
        "val_predictions = model.predict(\n",
        "    source=str((VALID_DIR).resolve()),\n",
        "    save=True,\n",
        "    conf=CONFIDENCE_THRESHOLD\n",
        ")\n",
        "\n",
        "if val_predictions:\n",
        "    predictions_save_dir = val_predictions[0].save_dir\n",
        "    print(f\"\\nPredictions saved to '{predictions_save_dir}'.\\n\")\n",
        "else:\n",
        "    print(\"No predictions were made.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiengQi7uLhN"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3oybidjHhP6"
      },
      "source": [
        "# object detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVYdC-yUHAcF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "\n",
        "# Define the directory where the predictions are saved\n",
        "prediction_dir = 'runs/detect/predict'\n",
        "\n",
        "# List all images in the prediction directory\n",
        "images = os.listdir(prediction_dir)\n",
        "\n",
        "# Display up to 10 images with predictions\n",
        "num_images_to_display = min(10, len(images))  # Ensure we don't exceed the number of available images\n",
        "fig, axes = plt.subplots(1, num_images_to_display, figsize=(200, 100))  # Create a row of subplots\n",
        "\n",
        "for i in range(num_images_to_display):\n",
        "    img_path = os.path.join(prediction_dir, images[i])  # Get image path\n",
        "    img = mpimg.imread(img_path)  # Load the image\n",
        "    axes[i].imshow(img)  # Show image on the corresponding subplot\n",
        "    axes[i].axis('off')  # Disable axis for the subplot\n",
        "\n",
        "plt.tight_layout()  # Adjust spacing between images\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSlGCa-Kvbgx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ufji5EqgqvNS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.spatial.distance import euclidean\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load YOLOv5 model (using YOLOv5s as specified)\n",
        "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Placeholder for a depth estimation model\n",
        "class DepthEstimationModel:\n",
        "    def predict(self, image):\n",
        "        \"\"\"\n",
        "        Generate a simulated depth map (replace with an actual depth estimation model if available).\n",
        "        \"\"\"\n",
        "        h, w = image.shape[:2]\n",
        "        depth_map = np.linspace(30, 80, w).reshape(1, -1).repeat(h, axis=0)  # Depth gradient from 30m to 80m\n",
        "        return depth_map\n",
        "\n",
        "depth_model = DepthEstimationModel()\n",
        "\n",
        "def estimate_distances_kitti(prediction_dir, output_dir, num_images_to_display=5):\n",
        "    \"\"\"\n",
        "    Function to calculate distances between detected vehicles in KITTI dataset images,\n",
        "    annotate them, and save the results in a new directory.\n",
        "\n",
        "    Args:\n",
        "        prediction_dir (str): Directory containing the KITTI images with detected objects.\n",
        "        output_dir (str): Directory to save annotated images with distance information.\n",
        "        num_images_to_display (int): Number of images to display with distance annotations.\n",
        "\n",
        "    Returns:\n",
        "        list: Distances between objects for each image.\n",
        "    \"\"\"\n",
        "    # Ensure prediction directory exists\n",
        "    if not os.path.exists(prediction_dir):\n",
        "        raise ValueError(f\"Directory '{prediction_dir}' does not exist!\")\n",
        "\n",
        "    images = [img for img in os.listdir(prediction_dir) if img.endswith(('png', 'jpg', 'jpeg'))]\n",
        "    if not images:\n",
        "        raise ValueError(f\"No image files found in directory '{prediction_dir}'!\")\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    all_distances = []  # Store distances for all images\n",
        "    num_images_to_display = min(num_images_to_display, len(images))  # Limit images to display\n",
        "    fig, axes = plt.subplots(1, num_images_to_display, figsize=(20, 10))\n",
        "\n",
        "    for i, img_file in enumerate(images):\n",
        "        img_path = os.path.join(prediction_dir, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not load image at path '{img_path}'. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Perform object detection\n",
        "        results = yolo_model(img_rgb)\n",
        "        detections = results.xyxy[0].cpu().numpy()\n",
        "\n",
        "        # Filter for vehicles (car=2, motorcycle=3, bus=5, truck=7)\n",
        "        vehicle_detections = [d for d in detections if int(d[5]) in [2, 3, 5, 7]]\n",
        "\n",
        "        # Generate depth map\n",
        "        depth_map = depth_model.predict(img_rgb)\n",
        "\n",
        "        # Annotate image and calculate distances\n",
        "        distances = []\n",
        "        vehicle_centroids = []\n",
        "        for det in vehicle_detections:\n",
        "            x1, y1, x2, y2, conf, cls = map(int, det[:6])\n",
        "            vehicle_depth = depth_map[y1:y2, x1:x2].mean()  # Average depth within the bounding box\n",
        "            centroid = ((x1 + x2) // 2, (y1 + y2) // 2, vehicle_depth)\n",
        "            vehicle_centroids.append(centroid)\n",
        "\n",
        "            # Draw bounding box and label\n",
        "            label = f\"{int(cls)}: {vehicle_depth:.1f}m\"\n",
        "            cv2.rectangle(img_rgb, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "            cv2.putText(img_rgb, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "\n",
        "        # Calculate pairwise distances between vehicles\n",
        "        for j in range(len(vehicle_centroids)):\n",
        "            for k in range(j + 1, len(vehicle_centroids)):\n",
        "                dist = euclidean(vehicle_centroids[j], vehicle_centroids[k])\n",
        "                distances.append(dist)\n",
        "\n",
        "        all_distances.append((img_file, distances))\n",
        "\n",
        "        # Save the annotated image\n",
        "        output_path = os.path.join(output_dir, img_file)\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        # Display the annotated image\n",
        "        if i < num_images_to_display:\n",
        "            axes[i].imshow(img_rgb)\n",
        "            axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return all_distances\n",
        "\n",
        "# Example usage\n",
        "prediction_dir = 'runs/detect/predict'  # Directory with detected images from KITTI dataset\n",
        "output_dir = 'runs/detect/distance_estimation'  # Directory to save annotated images\n",
        "distances = estimate_distances_kitti(prediction_dir, output_dir)\n",
        "\n",
        "# Print distances between objects for each image\n",
        "for img_file, dist in distances:\n",
        "    print(f\"Image: {img_file}, Distances: {dist}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EIVQzo8tl0V"
      },
      "outputs": [],
      "source": [
        "# After saving the annotated image, display them if needed\n",
        "def display_images_from_directory(output_dir, num_images_to_display=5):\n",
        "    \"\"\"\n",
        "    Function to display the saved annotated images from the output directory.\n",
        "\n",
        "    Args:\n",
        "        output_dir (str): Directory containing the annotated images.\n",
        "        num_images_to_display (int): Number of images to display.\n",
        "    \"\"\"\n",
        "    images = [img for img in os.listdir(output_dir) if img.endswith(('png', 'jpg', 'jpeg'))]\n",
        "    if len(images) == 0:\n",
        "        print(f\"No images found in output directory '{output_dir}'.\")\n",
        "        return\n",
        "\n",
        "    num_images_to_display = min(num_images_to_display, len(images))\n",
        "    fig, axes = plt.subplots(1, num_images_to_display, figsize=(200, 50))\n",
        "\n",
        "    for i, img_file in enumerate(images[:num_images_to_display]):\n",
        "        img_path = os.path.join(output_dir, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        axes[i].imshow(img_rgb)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage to display images after processing\n",
        "display_images_from_directory(output_dir, num_images_to_display=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-AVzj9zD3WB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 976194,
          "sourceId": 1650695,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30786,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}